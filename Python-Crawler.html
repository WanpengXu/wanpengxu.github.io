<!DOCTYPE html>
<html lang="default">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="baidu-site-verification" content="code-dlFXc2180h" />


    <meta name="google-site-verification" content="qlTU_n7RT-JIFfLGMsgqxNsTEkVlsWnOfvoPzzHzSR0" />
    <!-- <meta name="google-site-verification" content="wNw6ZIFTz_hFtiJ2w108gXZcLcg3e8tLeSGIC36Wn_M" /> -->


    <meta name="author" content="许">





<title>Python爬虫基础 | 须臾所学之野</title>



    <link rel="icon" href="/favicon.png">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    






    
    
        <script>
    MathJax = {
        tex: {
            // 行内公式标志
            inlineMath: [
                ['$', '$']
            ],
            // 块级公式标志
            displayMath: [
                ['$$', '$$']
            ],
            // 下面两个主要是支持渲染某些公式，可以自己了解
            processEnvironments: true,
            processRefs: true,
        },
        options: {
            // 跳过渲染的标签
            skipHtmlTags: ['noscript', 'style', 'textarea', 'pre', 'code'],
            // 跳过mathjax处理的元素的类名，任何元素指定一个类 tex2jax_ignore 将被跳过，多个累=类名'class1|class2'
            ignoreHtmlClass: 'tex2jax_ignore',
        },
        // 这里可能是因为我的MathJax2仍有残留，导致行间公式被渲染成了type="math/tex"，所以要用这种2、3版本混合查找方式进行渲染
        // 这样可能效率低，有机会再改。
        options: {
            renderActions: {
                /* add a new named action not to override the original 'find' action */
                find_script_mathtex: [10, function (doc) {
                    for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                        const display = !!node.type.match(/; *mode=display/);
                        const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                        const text = document.createTextNode('');
                        node.parentNode.replaceChild(text, node);
                        math.start = {
                            node: text,
                            delim: '',
                            n: 0
                        };
                        math.end = {
                            node: text,
                            delim: '',
                            n: 0
                        };
                        doc.math.push(math);
                    }
                }, '']
            }
        },
        svg: {
            fontCache: 'global',
        },
    };
</script>

<script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<!-- <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.bootcdn.net/ajax/libs/mathjax/3.1.2/es5/tex-mml-chtml.min.js">
</script> -->
    



<meta name="generator" content="Hexo 6.3.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Xuwp&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                    <a class="menu-item" href="/link">Links</a>
                
                    <a class="menu-item" href="https://xuwp.top/cv-en/">CV(Profile)</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Xuwp&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                    <a class="menu-item" href="/link">Links</a>
                
                    <a class="menu-item" href="https://xuwp.top/cv-en/">CV(Profile)</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6;    // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function () {
            tocbot.refresh(obj_merge(tocbot_default_config, { hasInnerContainers: true }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function () {
        tocbot.init(obj_merge(tocbot_default_config, { collapseDepth: 1 }));
    });

    function expandToc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, { collapseDepth: expanded ? 1 : DEPTH_MAX }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Python爬虫基础</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">许</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">November 23, 2023&nbsp;&nbsp;14:05:08</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/%E5%B7%A5%E5%85%B7%E6%80%A7%E6%8A%80%E6%9C%AF/">工具性技术</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <blockquote>
<p>repo: <a target="_blank" rel="noopener" href="https://github.com/wistbean/learn_python3_spider">https://github.com/wistbean/learn_python3_spider</a><br>靶场： <a target="_blank" rel="noopener" href="http://www.spiderbuf.cn/">http://www.spiderbuf.cn/</a>, <a target="_blank" rel="noopener" href="https://scrape.center/">https://scrape.center/</a></p>
</blockquote>
<h1 id="Packet-Sniffing-Capturing"><a href="#Packet-Sniffing-Capturing" class="headerlink" title="Packet Sniffing / Capturing"></a>Packet Sniffing / Capturing</h1><p>HTTP 请求方式：<strong>GET, POST</strong>, PUT, DELETE, HEAD, OPTIONS, TRACE</p>
<h2 id="GET-Request"><a href="#GET-Request" class="headerlink" title="GET Request"></a>GET Request</h2><p>在百度搜索框输入“toefl”，点击“百度一下”，获得的url如下，服务器<code>https://www.baidu.com/s</code>通过<code>?</code>进行GET请求，GET请求以键值对方式传递参数，经url格式化后如下。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231123145735034.png" alt="image.png"></p>
<h2 id="POST-Request"><a href="#POST-Request" class="headerlink" title="POST Request"></a>POST Request</h2><p>在百度搜索页面中点击“登陆”，输入”testusername”作为用户名，”testpassword”作为密码，点击“登陆”，在控制台中的 Network 选项中可以看到名为 <code>api/?login</code> 的 request，从 Headers 中可以看出这是一个 post 请求，在 Payload 中可以看出 post 请求以 form 表单方式传递参数。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231123150417305.png" alt="image.png"></p>
<h2 id="Request-Header"><a href="#Request-Header" class="headerlink" title="Request Header"></a>Request Header</h2><p>Http Request 除了提交参数外，还会有一些用于定义其自身的信息，如 Accept、Host、Cookie、User-Agent等。其中，Cookie是服务器保存在浏览器（客户端）中的用户信息，用于模拟用户登录状态；User-Agent是用户代理（一般是浏览器）信息，用于模拟正常的浏览器行为而非程序爬虫行为。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231123152436973.png" alt="image.png"></p>
<p>事实上，Request 由 Request Line, Request Header 和 Request Body 组成。其中 GET Request 不包含 Request Body。</p>
<h2 id="Response"><a href="#Response" class="headerlink" title="Response"></a>Response</h2><p>Status Line, Response Header 和 Response Body 共同组成一个 Response。</p>
<p>Status Line 由 Status Code 和 描述组成，如 200 OK 代表成功。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231123153356107.png" alt="image.png"></p>
<p>Response Header 包括服务器信息和响应体的信息</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231123154744231.png" alt="image.png"></p>
<p>Response Body 即为进行 Request 后的网页，可以通过渲染成为可视化的网页。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231123155251004.png" alt="image.png"></p>
<h1 id="Capturing-Mobile-Phone-Packets"><a href="#Capturing-Mobile-Phone-Packets" class="headerlink" title="Capturing  Mobile Phone Packets"></a>Capturing  Mobile Phone Packets</h1><p>浏览器自带控制台无法满足更专业的抓包需求，需要使用专业工具，如 Fiddler 或 BurpSuite。</p>
<p>关于 BurpSuite 的下载、安装、破解，见：<a target="_blank" rel="noopener" href="https://ccalt.cn/2023/04/04/BurpSuite%E5%85%A8%E5%B9%B3%E5%8F%B0%E7%A0%B4%E8%A7%A3%E9%80%9A%E7%94%A8-%E8%87%B3%E4%BB%8A%E5%8F%AF%E7%94%A8/">BurpSuite全平台破解通用-至今可用 - SaberCC Blog (ccalt.cn)</a><br>BurpSuite 的基础使用，见官方文档：<a target="_blank" rel="noopener" href="https://portswigger.net/burp/documentation/desktop/getting-started/intercepting-http-traffic?utm_source=burp_suite_professional&amp;utm_medium=learn_tab&amp;utm_campaign=onboarding">Intercepting HTTP traffic with Burp Proxy - PortSwigger</a></p>
<p>接下来记录移动设备抓包，以 iPhone 为例。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231124103050195.png" alt="image.png"></p>
<p>先跳过，iPhone和MacBook在校园网下不在同一网段，mac没法开热点。</p>
<h1 id="Urllib-Library"><a href="#Urllib-Library" class="headerlink" title="Urllib Library"></a>Urllib Library</h1><p><code>urllib</code> 是 python 的内建库，包括 4 个模块：<code>request</code>, <code>error</code>, <code>parse</code>, <code>robotparser</code></p>
<p>模块的功能都是顾名思义的，不用说了，下面进行 <code>request</code> 模块的使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response = request.urlopen(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;my_baidu.html&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(response.read().decode(<span class="string">&quot;utf-8&quot;</span>))</span><br></pre></td></tr></table></figure>
<p>使用 <code>urlopen</code> 方法即可对 url 发起 GET Request，其 Response Body 会作为方法的返回值。<br>将 response body 保存为 HTML 文件即可在本地打开。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231124113936770.png" alt="image.png"></p>
<p><code>urlopen</code> 方法的参数说明，主要使用 <code>url</code>, <code>data</code>, <code>timeout</code> 参数。<br>其中，<code>data</code> 参数用于传递 post 请求的参数，若其为空则 <code>urlopen</code> 为 GET Request，若不为空则为 POST Request。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231124114751375.png" alt="image.png"></p>
<p>此时，在终端中将代理临时设置为 burpsuite 可捕获的代理，即可在 burpsuite 中看到 urllib 库发送的 GET Request。</p>
<p>临时代理设置命令：<code>export http_proxy=&#39;http://127.0.0.1:8080&#39;</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231124120617965.png" alt="image.png"></p>
<p>可以看到 Request Header 中的 User-Agent 直接显示了 Python-urllib/3.9</p>
<p>为了欺骗服务器该 Request 是浏览器发出的正常访问行为，需要使用<code>urllib.Request</code>方法来定义具体的 Requset。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231124121330347.png" alt="image.png"></p>
<p>简单查看一下 Requset 方法，发现其除了可以指定 Requset 的 url 和 data 外，还可以指定 header 和 method。</p>
<p>这时可以使用靶场练习，以 Spiderbuf E01 为例。</p>
<p>使用浏览器进入关卡，使用默认账户密码，点击“登陆”，提交 POST Request。Burp 截获到 POST Request，对其进行分析。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231124131852885.png" alt="image.png"></p>
<p>发现提交的 payload aka form data 是明文。此外，也获取到了 header 中的正常浏览器信息 User-Agent，我们可以用这些信息来模拟浏览器登录。</p>
<p>根据截获的 request header 和 request body 中的信息及前面 <code>urllib</code> 的简单应用，可以写出以下脚本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import ssl</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request, parse</span><br><span class="line"></span><br><span class="line"><span class="comment"># context = ssl._create_unverified_context()    # https 连接</span></span><br><span class="line">context = <span class="literal">None</span>  <span class="comment"># http 连接</span></span><br><span class="line">url = <span class="string">&#x27;http://www.spiderbuf.cn/e01/login&#x27;</span>   <span class="comment"># 这里一定要向login页面发送</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.6045.159 Safari/537.36&quot;</span></span><br><span class="line">&#125; </span><br><span class="line">payload = &#123;</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;admin&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">payload = <span class="built_in">bytes</span>(parse.urlencode(payload), <span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line"></span><br><span class="line">req = request.Request(url, data=payload, headers=headers, method=<span class="string">&quot;POST&quot;</span>)</span><br><span class="line">res = request.urlopen(req, context=context)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;my_spiderbuf_e01.html&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(res.read().decode(<span class="string">&quot;utf-8&quot;</span>))</span><br></pre></td></tr></table></figure>
<p>运行，得到报错 <code>urllib.error.HTTPError: HTTP Error 307: Temporary Redirect</code>，但这反而说明代码语义正确，因为这个关卡在身份验证通过后就是会重定向到另一个网页，如果想要处理这个 error，就需要用到前面提到的 <code>urllib.error</code> 模块。</p>
<h1 id="Requests-Library"><a href="#Requests-Library" class="headerlink" title="Requests Library"></a>Requests Library</h1><p><code>requests</code> 库基于 <code>urllib</code> 内建库开发，因此比其更强。</p>
<p>示例见 jupyter notebook</p>
<h1 id="Regular-Expression"><a href="#Regular-Expression" class="headerlink" title="Regular Expression"></a><strong>Reg</strong>ular <strong>Exp</strong>ression</h1><p>正则表达式语法</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>转义字符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>d</td>
<td>digita，任意数字，$[0, 9]$</td>
</tr>
<tr>
<td>D</td>
<td>$\neg$d，任意非数字，$\mathbb{U}-[0, 9]$</td>
</tr>
<tr>
<td>w</td>
<td>word，传统可识别字符，$[0, 9]+[a, z]+[A, z]+\{_\}$</td>
</tr>
<tr>
<td>W</td>
<td>$\neg$w</td>
</tr>
<tr>
<td>n</td>
<td>newline，换行</td>
</tr>
<tr>
<td>r</td>
<td>return，回车</td>
</tr>
<tr>
<td>t</td>
<td>tab，制表</td>
</tr>
<tr>
<td>s</td>
<td>space，所有空白字符</td>
</tr>
<tr>
<td>S</td>
<td>$\neg$s</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>标记字符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>^</td>
<td>字符串起始符</td>
</tr>
<tr>
<td>$</td>
<td>字符串结束符</td>
</tr>
<tr>
<td>.</td>
<td>通配符，匹配一个任意字符（除\n）</td>
</tr>
<tr>
<td>[…]</td>
<td>匹配一个标记的字符</td>
</tr>
<tr>
<td><sup><a href="#fn_..." id="reffn_...">...</a></sup></td>
<td>匹配一个未标记的字符</td>
</tr>
<tr>
<td>()</td>
<td>子表达式 / 捕获组</td>
</tr>
<tr>
<td>&#124;</td>
<td>或逻辑</td>
</tr>
<tr>
<td>{}</td>
<td>数量限定符，{n}代表匹配前面的字符n次，{n,m}代表匹配前面的字符至少n次至多m次，m可为空</td>
</tr>
<tr>
<td>*</td>
<td>{0,}</td>
</tr>
<tr>
<td>+</td>
<td>{1,}</td>
</tr>
<tr>
<td>?</td>
<td>{0,1}</td>
</tr>
</tbody>
</table>
</div>
<p>在 python 中使用正则表达式使用 re 库，<code>re.findall</code> 方法类似于 <code>Ctrl+F</code>，<code>re.sub</code> 方法类似于 <code>Ctrl+R</code>。</p>
<p><code>re.findall</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;&#x27;&#x27;I am trying to list some unit conversion: </span></span><br><span class="line"><span class="string">1m=10dm=100cm=1000mm</span></span><br><span class="line"><span class="string">1L=10dL=1000mL&#x27;&#x27;&#x27;</span></span><br><span class="line">res = re.findall(<span class="string">&quot;\d+[a-zA-Z]+&quot;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;1m&#x27;, &#x27;10dm&#x27;, &#x27;100cm&#x27;, &#x27;1000mm&#x27;, &#x27;1L&#x27;, &#x27;10dL&#x27;, &#x27;1000mL&#x27;]</span><br></pre></td></tr></table></figure>
<p><code>re.sub</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">content = <span class="string">&#x27;&#x27;&#x27;I am trying to list some unit conversion: </span></span><br><span class="line"><span class="string">1m=10dm=100cm=1000mm</span></span><br><span class="line"><span class="string">1L=10dL=1000mL&#x27;&#x27;&#x27;</span></span><br><span class="line">res = re.sub(<span class="string">&quot;=&quot;</span>, <span class="string">&quot; &quot;</span>, content)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">I am trying to list some unit conversion: </span><br><span class="line">1m 10dm 100cm 1000mm</span><br><span class="line">1L 10dL 1000mL</span><br></pre></td></tr></table></figure>
<p><code>re.complie</code>，将正则表达式及标记保存为正则表达式对象以便复用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">&quot;\d+[a-z]+&quot;</span>, re.I)</span><br><span class="line">content = <span class="string">&#x27;&#x27;&#x27;I am trying to list some unit conversion: </span></span><br><span class="line"><span class="string">1m=10dm=100cm=1000mm</span></span><br><span class="line"><span class="string">1L=10dL=1000mL&#x27;&#x27;&#x27;</span></span><br><span class="line">res = re.findall(pattern, content)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;1m&#x27;, &#x27;10dm&#x27;, &#x27;100cm&#x27;, &#x27;1000mm&#x27;, &#x27;1L&#x27;, &#x27;10dL&#x27;, &#x27;1000mL&#x27;]</span><br></pre></td></tr></table></figure>
<h1 id="Demo-1-当当网-Top-500-五星书籍"><a href="#Demo-1-当当网-Top-500-五星书籍" class="headerlink" title="Demo 1: 当当网 Top 500 五星书籍"></a>Demo 1: 当当网 Top 500 五星书籍</h1><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>目标url：<a target="_blank" rel="noopener" href="http://bang.dangdang.com/books/fivestars/01.00.00.00.00.00-recent30-0-0-1-1">http://bang.dangdang.com/books/fivestars/01.00.00.00.00.00-recent30-0-0-1-1</a></p>
<p>1. 每页显示 20 本书</p>
<p>2.  页数对应 url 的最后一个参数，可用变量实现翻页</p>
<p>3. </p>
<p>GET Request</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231127163114010.png" alt="image-20231127163113329"></p>
<p>Response</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231127164151014.png" alt="image-20231127164150493"></p>
<p>4. 所需信息</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231127170222330.png" alt="image-20231127170221794"></p>
<p>排名、图片地址、书名、推荐指数（补充分析发现该好评榜所有书籍均为5星）、作者、五星评分次数、价格</p>
<p>Ctrl + F 定位到信息所在标签，<code>&lt;li&gt;</code>标签。找到待过滤的所需信息。这里在 Element 标签下查看。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231127202331413.png" alt="image-20231127202330797"></p>
<h2 id="程序思路"><a href="#程序思路" class="headerlink" title="程序思路"></a>程序思路</h2><ol>
<li>使用 <code>page</code> 变量指定页面</li>
<li>使用 GET Request 进行页面请求</li>
<li>使用 regex 对 HTML Response 进行所需信息过滤</li>
<li>把信息存储到文本文档中（后面可能会学习存储到数据库）</li>
</ol>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p><strong>!NOTE!</strong> 使用这份代码爬到的信息会有错位问题，仅可作为练习用，解释见下章代码实现节。</p>
<h3 id="写入到-json-文件"><a href="#写入到-json-文件" class="headerlink" title="写入到 json 文件"></a>写入到 json 文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request_html</span>(<span class="params">url</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Cookie&quot;</span>: <span class="string">&quot;ddscreen=2; ddscreen=2; dest_area=country_id%3D9000%26province_id%3D111%26city_id%20%3D0%26district_id%3D0%26town_id%3D0; __permanent_id=20231125224536629264140414679707403; ddscreen=2; __visit_id=20231127162657511199966560194631544; __out_refer=; pos_6_start=1701075618952; pos_6_end=1701075619070; __rpm=...1701075804280%7C...1701075808570; __trace_id=20231127170908374355067728566175250&quot;</span>,</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> res.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_result</span>(<span class="params">html</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    &lt;li&gt;.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;list_num.*?&gt;(.*?)\.&lt;/div&gt;.*? </span></span><br><span class="line"><span class="string">    &lt;div class=&quot;pic&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot;.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;name&quot;&gt;.*?title=&quot;(.*?)&quot;.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;star&quot;&gt;.*?&lt;span class=&quot;tuijian&quot;&gt;(.*?)推荐.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;publisher_info&quot;&gt;.*?title=&quot;(.*?)&quot;.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;biaosheng&quot;&gt;五星评分：&lt;span&gt;(.*?)次.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;price&quot;&gt;.*?&lt;span class=&quot;price_n&quot;&gt;&amp;yen;(.*?)&lt;/span&gt;.*?</span></span><br><span class="line"><span class="string">    &lt;/li&gt;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;li&gt;.*?&lt;div class=&quot;list_num.*?&gt;(.*?)\.&lt;/div&gt;.*? &lt;div class=&quot;pic&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot;.*?&lt;div class=&quot;name&quot;&gt;.*?title=&quot;(.*?)&quot;.*?&lt;div class=&quot;star&quot;&gt;.*?&lt;span class=&quot;tuijian&quot;&gt;(.*?)推荐.*?&lt;div class=&quot;publisher_info&quot;&gt;.*?title=&quot;(.*?)&quot;.*?&lt;div class=&quot;biaosheng&quot;&gt;五星评分：&lt;span&gt;(.*?)次.*?&lt;div class=&quot;price&quot;&gt;.*?&lt;span class=&quot;price_n&quot;&gt;&amp;yen;(.*?)&lt;/span&gt;.*?&lt;/li&gt;&#x27;</span>, re.S)</span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&quot;rank&quot;</span>: item[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&quot;image&quot;</span>: item[<span class="number">1</span>],</span><br><span class="line">            <span class="string">&quot;title&quot;</span>: item[<span class="number">2</span>],</span><br><span class="line">            <span class="string">&quot;recommend_index&quot;</span>: item[<span class="number">3</span>],</span><br><span class="line">            <span class="string">&quot;author&quot;</span>: item[<span class="number">4</span>],</span><br><span class="line">            <span class="string">&quot;5stars_number&quot;</span>: item[<span class="number">5</span>],</span><br><span class="line">            <span class="string">&quot;price&quot;</span>: item[<span class="number">6</span>],</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_item_to_json</span>(<span class="params">item</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;fivestars_books.json&quot;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.writelines(json.dumps(item, ensure_ascii=<span class="literal">False</span>) + (<span class="string">&#x27;,\n&#x27;</span> <span class="keyword">if</span> item[<span class="string">&quot;rank&quot;</span>]!=<span class="string">&quot;500&quot;</span> <span class="keyword">else</span> <span class="string">&#x27;\n&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;fivestars_books.json&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.writelines(<span class="string">&#x27;&#123;&quot;5stars_book&quot;:[\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">25</span>+<span class="number">1</span>):</span><br><span class="line">    url = <span class="string">f&quot;http://bang.dangdang.com/books/fivestars/01.00.00.00.00.00-recent30-0-0-1-<span class="subst">&#123;page&#125;</span>&quot;</span></span><br><span class="line">    html = request_html(url)</span><br><span class="line">    items = parse_result(html)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        write_item_to_json(item)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;fivestars_books.json&quot;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.writelines(<span class="string">&#x27;]&#125;\n&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>格式化后的 json文件 </p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231127200925898.png" alt="image-20231127200925274"></p>
<h3 id="写入到-csv-文件"><a href="#写入到-csv-文件" class="headerlink" title="写入到 csv 文件"></a>写入到 csv 文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request_html</span>(<span class="params">url</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Cookie&quot;</span>: <span class="string">&quot;ddscreen=2; ddscreen=2; dest_area=country_id%3D9000%26province_id%3D111%26city_id%20%3D0%26district_id%3D0%26town_id%3D0; __permanent_id=20231125224536629264140414679707403; ddscreen=2; __visit_id=20231127162657511199966560194631544; __out_refer=; pos_6_start=1701075618952; pos_6_end=1701075619070; __rpm=...1701075804280%7C...1701075808570; __trace_id=20231127170908374355067728566175250&quot;</span>,</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> res.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_result</span>(<span class="params">html</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    &lt;li&gt;.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;list_num.*?&gt;(.*?)\.&lt;/div&gt;.*? </span></span><br><span class="line"><span class="string">    &lt;div class=&quot;pic&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot;.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;name&quot;&gt;.*?title=&quot;(.*?)&quot;.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;star&quot;&gt;.*?&lt;span class=&quot;tuijian&quot;&gt;(.*?)推荐.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;publisher_info&quot;&gt;.*?title=&quot;(.*?)&quot;.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;biaosheng&quot;&gt;五星评分：&lt;span&gt;(.*?)次.*?</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;price&quot;&gt;.*?&lt;span class=&quot;price_n&quot;&gt;&amp;yen;(.*?)&lt;/span&gt;.*?</span></span><br><span class="line"><span class="string">    &lt;/li&gt;</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    pattern = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;li&gt;.*?&lt;div class=&quot;list_num.*?&gt;(.*?)\.&lt;/div&gt;.*? &lt;div class=&quot;pic&quot;&gt;.*?&lt;img src=&quot;(.*?)&quot;.*?&lt;div class=&quot;name&quot;&gt;.*?title=&quot;(.*?)&quot;.*?&lt;div class=&quot;star&quot;&gt;.*?&lt;span class=&quot;tuijian&quot;&gt;(.*?)推荐.*?&lt;div class=&quot;publisher_info&quot;&gt;.*?title=&quot;(.*?)&quot;.*?&lt;div class=&quot;biaosheng&quot;&gt;五星评分：&lt;span&gt;(.*?)次.*?&lt;div class=&quot;price&quot;&gt;.*?&lt;span class=&quot;price_n&quot;&gt;&amp;yen;(.*?)&lt;/span&gt;.*?&lt;/li&gt;&#x27;</span>, re.S)</span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;fivestars_books.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    csv_writer = csv.writer(f)</span><br><span class="line">    csv_writer.writerow([<span class="string">&quot;Rank&quot;</span>, <span class="string">&quot;Image&quot;</span>, <span class="string">&quot;Title&quot;</span>, <span class="string">&quot;Recommend Index&quot;</span>, <span class="string">&quot;Author&quot;</span>, <span class="string">&quot;5 Stars Number&quot;</span>, <span class="string">&quot;Price&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">25</span>+<span class="number">1</span>):</span><br><span class="line">        url = <span class="string">f&quot;http://bang.dangdang.com/books/fivestars/01.00.00.00.00.00-recent30-0-0-1-<span class="subst">&#123;page&#125;</span>&quot;</span></span><br><span class="line">        html = request_html(url)</span><br><span class="line">        items = parse_result(html)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            csv_writer.writerow(item)</span><br></pre></td></tr></table></figure>
<p>格式化后的 csv 文件</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231127201207582.png" alt="image-20231127201207013"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>Rank</strong></th>
<th><strong>Image</strong></th>
<th><strong>Title</strong></th>
<th><strong>Recommend Index</strong></th>
<th><strong>Author</strong></th>
<th><strong>5 Stars Number</strong></th>
<th><strong>Price</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1</strong></td>
<td><a target="_blank" rel="noopener" href="http://img3m8.ddimg.cn/92/24/29628218-1_l_1698390538.jpg">http://img3m8.ddimg.cn/92/24/29628218-1_l_1698390538.jpg</a></td>
<td>人间处方：茅盾文学奖得主梁晓声的人生哲学</td>
<td>99.8%</td>
<td>梁晓声</td>
<td>510</td>
<td>27.50</td>
</tr>
<tr>
<td><strong>2</strong></td>
<td><a target="_blank" rel="noopener" href="http://img3m0.ddimg.cn/36/32/29647170-1_l_1699250671.jpg">http://img3m0.ddimg.cn/36/32/29647170-1_l_1699250671.jpg</a></td>
<td>给孩子的最美散文（2023新版） 史铁生、季羡林、迟子建等文学大家诚意之作</td>
<td>100%</td>
<td>史铁生 季羡林 迟子建 等 著，磨铁文化 出品</td>
<td>508</td>
<td>39.60</td>
</tr>
<tr>
<td><strong>3</strong></td>
<td><a target="_blank" rel="noopener" href="http://img3m8.ddimg.cn/76/6/29627608-1_l_1695016596.jpg">http://img3m8.ddimg.cn/76/6/29627608-1_l_1695016596.jpg</a></td>
<td>女性的选择（女孩，别忘了，你才是做选择的那个人！）</td>
<td>99.7%</td>
<td>坂东真理子 著 快读慢活 出品</td>
<td>301</td>
<td>29.50</td>
</tr>
</tbody>
</table>
</div>
<h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="挑选所需信息"><a href="#挑选所需信息" class="headerlink" title="挑选所需信息"></a>挑选所需信息</h3><p>有时候所需信息会在多个标签出现，这时最好从标签内的属性中捕获文字，不要捕获渲染出来的（显示在屏幕上的）文字，因为尺寸限制，屏幕上的文字可能显示不全，出现<code>领导力：领导者性格与知人善任（知名DISC推广者、喜马拉雅头部荐...</code> 这种情况。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231127184004175.png" alt="image-20231127184003564"></p>
<h3 id="怎么写-regex"><a href="#怎么写-regex" class="headerlink" title="怎么写 regex"></a>怎么写 regex</h3><p>可以直接复制渲染某个条目的所有代码，然后将其中不需要的信息（非定位非捕获）更换为任意字符 regex；将其中需要的信息更换为任意字符捕获组 regex。</p>
<p>任意字符：<code>.*?</code>，用于字符串跳过</p>
<p>任意字符捕获组：<code>(.*?)</code>，用于捕获定位捕获组内的所有字符</p>
<p>捕获组前后最好都有定位字符串，前字符串最好从共同的标签（<code>&lt;div&gt;</code>）开始，到紧挨着捕获组的字符结束；后字符串从紧贴捕获组的字符开始</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>前定位字符串</th>
<th>捕获组</th>
<th>后定位字符串</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>&lt;div class=&quot;pic&quot;&gt;.*?&lt;img src=&quot;</code></td>
<td><code>(.*?)</code></td>
<td><code>&quot;.*?</code></td>
</tr>
<tr>
<td><code>&lt;div class=&quot;name&quot;&gt;.*?title=&quot;</code></td>
<td><code>(.*?)</code></td>
<td><code>&quot;.*?</code></td>
</tr>
<tr>
<td><code>&lt;div class=&quot;star&quot;&gt;.*?&lt;span class=&quot;tuijian&quot;&gt;</code></td>
<td><code>(.*?)</code></td>
<td><code>推荐.*?</code></td>
</tr>
<tr>
<td><code>&lt;div class=&quot;publisher_info&quot;&gt;.*?title=&quot;</code></td>
<td><code>(.*?)</code></td>
<td><code>&quot;.*?</code></td>
</tr>
<tr>
<td><code>&lt;div class=&quot;biaosheng&quot;&gt;五星评分：&lt;span&gt;</code></td>
<td><code>(.*?)</code></td>
<td><code>次.*?</code></td>
</tr>
<tr>
<td><code>&lt;div class=&quot;price&quot;&gt;.*?&lt;span class=&quot;price_n&quot;&gt;&amp;yen;</code></td>
<td><code>(.*?)</code></td>
<td><code>&lt;/span&gt;.*?</code></td>
</tr>
</tbody>
</table>
</div>
<h1 id="BeautifulSoup-Library"><a href="#BeautifulSoup-Library" class="headerlink" title="BeautifulSoup Library"></a>BeautifulSoup Library</h1><p>既然 regex 并不难写，自然也会有库帮助我们自动提取信息。</p>
<h2 id="方法测试"><a href="#方法测试" class="headerlink" title="方法测试"></a>方法测试</h2><p>见ipynb</p>
<h2 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request_html</span>(<span class="params">url</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Cookie&quot;</span>: <span class="string">&quot;ddscreen=2; dest_area=country_id%3D9000%26province_id%3D111%26city_id%20%3D0%26district_id%3D0%26town_id%3D0; __permanent_id=20231125224536629264140414679707403; __rpm=...1701075804280%7C...1701075808570; __visit_id=20231128081738921251655595867899598; __out_refer=; __trace_id=20231128081738922580451376020939735&quot;</span>,</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0&quot;</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> res.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_result</span>(<span class="params">html</span>):</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line"></span><br><span class="line">    items = []</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> soup.select(<span class="string">&#x27;li&#x27;</span>):</span><br><span class="line">        rank_elem = li.select_one(<span class="string">&#x27;.list_num&#x27;</span>)</span><br><span class="line">        img_elem = li.select_one(<span class="string">&#x27;.pic img&#x27;</span>)</span><br><span class="line">        title_elem = li.select_one(<span class="string">&#x27;.name a&#x27;</span>)</span><br><span class="line">        recommend_elem = li.select_one(<span class="string">&#x27;.tuijian&#x27;</span>)</span><br><span class="line">        author_elem = li.select_one(<span class="string">&#x27;.publisher_info a&#x27;</span>)</span><br><span class="line">        stars_elem = li.select_one(<span class="string">&#x27;.biaosheng span&#x27;</span>)</span><br><span class="line">        price_elem = li.select_one(<span class="string">&#x27;.price .price_n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="literal">None</span> <span class="keyword">in</span> [rank_elem, img_elem, title_elem, recommend_elem, author_elem, stars_elem, price_elem]:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        </span><br><span class="line">        rank = rank_elem.text[:-<span class="number">1</span>]</span><br><span class="line">        image = img_elem[<span class="string">&#x27;src&#x27;</span>]</span><br><span class="line">        title = title_elem[<span class="string">&#x27;title&#x27;</span>]</span><br><span class="line">        recommend_index = recommend_elem.text</span><br><span class="line">        <span class="comment"># print(author_elem)</span></span><br><span class="line">        <span class="comment"># author = author_elem[&#x27;title&#x27;]</span></span><br><span class="line">        author = author_elem.get(<span class="string">&#x27;title&#x27;</span>, <span class="string">&#x27;None&#x27;</span>)   <span class="comment"># 使用 get() 方法代替重载 __getitem__() / [] 避免空键 KeyError</span></span><br><span class="line">        stars_number = stars_elem.text</span><br><span class="line">        price = price_elem.text</span><br><span class="line"></span><br><span class="line">        item = &#123;</span><br><span class="line">            <span class="string">&quot;Rank&quot;</span>: rank,</span><br><span class="line">            <span class="string">&quot;Image&quot;</span>: image,</span><br><span class="line">            <span class="string">&quot;Title&quot;</span>: title,</span><br><span class="line">            <span class="string">&quot;Recommend Index&quot;</span>: recommend_index,</span><br><span class="line">            <span class="string">&quot;Author&quot;</span>: author,</span><br><span class="line">            <span class="string">&quot;5 Stars Number&quot;</span>: stars_number,</span><br><span class="line">            <span class="string">&quot;Price&quot;</span>: price,</span><br><span class="line">        &#125;</span><br><span class="line">        items.append(item)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> items</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;fivestars_books_bs4.csv&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    csv_writer = csv.DictWriter(f, fieldnames=[<span class="string">&quot;Rank&quot;</span>, <span class="string">&quot;Image&quot;</span>, <span class="string">&quot;Title&quot;</span>, <span class="string">&quot;Recommend Index&quot;</span>, <span class="string">&quot;Author&quot;</span>, <span class="string">&quot;5 Stars Number&quot;</span>, <span class="string">&quot;Price&quot;</span>])</span><br><span class="line">    csv_writer.writeheader()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">25</span>+<span class="number">1</span>):</span><br><span class="line">        url = <span class="string">f&quot;http://bang.dangdang.com/books/fivestars/01.00.00.00.00.00-recent30-0-0-1-<span class="subst">&#123;page&#125;</span>&quot;</span></span><br><span class="line">        html = request_html(url)</span><br><span class="line">        items = parse_result(html)</span><br><span class="line">        csv_writer.writerows(items)</span><br></pre></td></tr></table></figure>
<p>效果比 regex 捕获的信息要好，因为可以判断是否有些信息为空，而不是捕获一些奇怪的东西。</p>
<p><strong>!NOTE!</strong> 如果使用 regex ，只要某些信息缺失，就会发生错位，把理应在后面捕获的信息提前捕获，这样爬到的错位信息是完全不对的！</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231128161530679.png" alt="image-20231128161529901"></p>
<p>这张图把下一个 item 的 title 当成 author 爬上来了</p>
<p>ps. 两次爬取间（2-3s左右），下一本书还多了1个五星评价。</p>
<h2 id="实现细节-1"><a href="#实现细节-1" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="通过-select-解析-HTML-获取信息"><a href="#通过-select-解析-HTML-获取信息" class="headerlink" title="通过 select 解析 HTML 获取信息"></a>通过 select 解析 HTML 获取信息</h3><p>先获取在某个元素内（<code>`）继承了指定类（</code>.`）的元素，但这些解析到的元素不一定是渲染书 item 的，只有当所有元素都不为空时才是描述书 item 的，所以要先进行非空检验。</p>
<h3 id="空键处理"><a href="#空键处理" class="headerlink" title="空键处理"></a>空键处理</h3><p>如果某些书没有提供作者信息，方括号<code>[]</code> / 重载的<code>__getitem__()</code>是不能从空key获取到value的，会报KeyError，这时要用<code>get()</code>方法提供空键时的返回值。</p>
<h1 id="Demo-2-豆瓣-Top-250-电影"><a href="#Demo-2-豆瓣-Top-250-电影" class="headerlink" title="Demo 2: 豆瓣 Top 250 电影"></a>Demo 2: 豆瓣 Top 250 电影</h1><h2 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h2><p>目标 url: <a target="_blank" rel="noopener" href="https://movie.douban.com/top250">https://movie.douban.com/top250</a></p>
<p>1. 每页显示 25 个电影</p>
<p>2. 通过 GET Request 参数  <code>?start=n</code> 指定从第 Top n+1 个电影开始显示</p>
<p>3. 所需信息</p>
<p>电影的排名、宣传图、名称、导演 / 演员、类型、评分、评价人数、简评</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231128193948429.png" alt="image-20231128193947794"></p>
<h2 id="程序思路-1"><a href="#程序思路-1" class="headerlink" title="程序思路"></a>程序思路</h2><p>和 Demo 1 差不多，获取html，解析信息，写入文件。</p>
<h2 id="代码实现-2"><a href="#代码实现-2" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request_url</span>(<span class="params">url</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Cookie&quot;</span>: <span class="string">&#x27;bid=r5NyipyS844; _pk_id.100001.4cf6=8d2637ab28beb521.1698656720.; dbcl2=&quot;220842516:kaSCAN2Yw5c&quot;; ck=u7Tj; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1701170775%2C%22https%3A%2F%2Fopen.weixin.qq.com%2F%22%5D; _pk_ses.100001.4cf6=1; __utma=30149280.1380904537.1698110791.1698656720.1701170775.3; __utmb=30149280.0.10.1701170775; __utmc=30149280; __utmz=30149280.1701170775.3.3.utmcsr=open.weixin.qq.com|utmccn=(referral)|utmcmd=referral|utmcct=/; __utma=223695111.603104195.1698656720.1698656720.1701170775.2; __utmb=223695111.0.10.1701170775; __utmc=223695111; __utmz=223695111.1701170775.2.2.utmcsr=open.weixin.qq.com|utmccn=(referral)|utmcmd=referral|utmcct=/; push_noty_num=0; push_doumail_num=0; __yadk_uid=bdyEdGw5LBo9dXxUEYdWEygyv1MkelW3; ll=&quot;118159&quot;; frodotk_db=&quot;ef37e0cdfc6851d8cda7a269f538f588&quot;; _vwo_uuid_v2=D3AA59641F59DCBAC831E95557CC131F7|984fdef9e1fa1ff456b997f6b8bb588b&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> res.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_html</span>(<span class="params">html</span>):</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    <span class="built_in">list</span> = soup.find(<span class="string">&quot;ol&quot;</span>, class_=<span class="string">&quot;grid_view&quot;</span>).find_all(<span class="string">&quot;li&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> <span class="built_in">list</span>:</span><br><span class="line">        rank = li.find(<span class="string">&quot;em&quot;</span>, class_=<span class="string">&quot;&quot;</span>).string</span><br><span class="line">        img = li.find(<span class="string">&#x27;a&#x27;</span>).find(<span class="string">&quot;img&quot;</span>).get(<span class="string">&quot;src&quot;</span>)</span><br><span class="line">        title = li.find(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;title&quot;</span>).string</span><br><span class="line">        author, <span class="built_in">type</span> = li.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&quot;&quot;</span>).text.strip().split(<span class="string">&quot;\n                            &quot;</span>)</span><br><span class="line">        score = li.find(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;rating_num&quot;</span>).string</span><br><span class="line">        <span class="comment"># review_count = li.find(&quot;div&quot;, class_=&quot;star&quot;).find(&quot;span&quot;, string=&quot;人评价&quot;).get_previous_sibling().string</span></span><br><span class="line">        review_count = li.find(<span class="string">&quot;div&quot;</span>, class_=<span class="string">&quot;star&quot;</span>).find_all(<span class="string">&quot;span&quot;</span>)[-<span class="number">1</span>].string</span><br><span class="line">        <span class="built_in">print</span>(rank, title)</span><br><span class="line">        best_comment_elem = li.find(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;inq&quot;</span>)</span><br><span class="line">        best_comment = best_comment_elem.string <span class="keyword">if</span> best_comment_elem != <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># yield &#123;</span></span><br><span class="line">        <span class="comment">#     &quot;Rank&quot;: rank,</span></span><br><span class="line">        <span class="comment">#     &quot;Image&quot;: img,</span></span><br><span class="line">        <span class="comment">#     &quot;Title&quot;: title,</span></span><br><span class="line">        <span class="comment">#     &quot;Author&quot;: author,</span></span><br><span class="line">        <span class="comment">#     &quot;Type&quot;: type,</span></span><br><span class="line">        <span class="comment">#     &quot;Score&quot;: score,</span></span><br><span class="line">        <span class="comment">#     &quot;Review Count&quot;: review_count,</span></span><br><span class="line">        <span class="comment">#     &quot;Best Comment&quot;: best_comment</span></span><br><span class="line">        <span class="comment"># &#125;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> [rank, img, title, author, <span class="built_in">type</span>, score, review_count, best_comment]</span><br><span class="line"></span><br><span class="line">max_col_width_zh = [<span class="number">0</span>] * <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_to_xlsx</span>(<span class="params">index, item</span>):</span><br><span class="line">    <span class="keyword">for</span> col, content <span class="keyword">in</span> <span class="built_in">enumerate</span>(item):</span><br><span class="line">        sheet.write(index, col, content)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(content.encode(<span class="string">&#x27;gb18030&#x27;</span>)) &gt; max_col_width_zh[col]:</span><br><span class="line">            max_col_width_zh[col] = <span class="built_in">len</span>(content.encode(<span class="string">&#x27;gb18030&#x27;</span>))</span><br><span class="line"></span><br><span class="line">book = xlwt.Workbook()</span><br><span class="line">sheet = book.add_sheet(<span class="string">&quot;豆瓣电影 Top 250&quot;</span>, cell_overwrite_ok=<span class="literal">True</span>)  <span class="comment"># 单元格覆写打开</span></span><br><span class="line">index = <span class="number">0</span></span><br><span class="line">headers = [<span class="string">&#x27;Rank&#x27;</span>, <span class="string">&#x27;Image&#x27;</span>, <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;Author&#x27;</span>, <span class="string">&#x27;Type&#x27;</span>, <span class="string">&#x27;Score&#x27;</span>, <span class="string">&#x27;Review Count&#x27;</span>, <span class="string">&#x27;Best Comment&#x27;</span>]</span><br><span class="line">write_to_xlsx(index, headers)</span><br><span class="line">index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">225</span>+<span class="number">1</span>, <span class="number">25</span>):</span><br><span class="line">    url = <span class="string">f&quot;https://movie.douban.com/top250?start=<span class="subst">&#123;start&#125;</span>&quot;</span></span><br><span class="line">    html = request_url(url)</span><br><span class="line">    items = parse_html(html)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        write_to_xlsx(index, item)</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">max_col_width = [width * <span class="number">256</span> <span class="keyword">for</span> width <span class="keyword">in</span>  max_col_width_zh]    <span class="comment"># 单位宽度 1/256</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col, width <span class="keyword">in</span> <span class="built_in">enumerate</span>(max_col_width):</span><br><span class="line">    sheet.col(col).width = width</span><br><span class="line"></span><br><span class="line">book.save(<span class="string">&quot;top250_movies.xls&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>效果，自适应宽度存在问题，不知道怎么回事，还是在 Excel 里双击列右侧吧。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231129000253204.png" alt="image-20231129000252605"></p>
<h2 id="实现细节-2"><a href="#实现细节-2" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="通过-find-解析-HTML-获取信息"><a href="#通过-find-解析-HTML-获取信息" class="headerlink" title="通过 find 解析 HTML 获取信息"></a>通过 find 解析 HTML 获取信息</h3><p><code>class_</code> 类似于 select 中的 <code>.</code>，找元素的子元素就 <code>find().find()</code> 这个操作类似 select 中的 <code> </code>。</p>
<h3 id="自适应宽度（有问题）"><a href="#自适应宽度（有问题）" class="headerlink" title="自适应宽度（有问题）"></a>自适应宽度（有问题）</h3><p>由于存在中文，需要先按 <code>gb18030</code> 编码再获取长度。excel中列宽的最小宽度是 1/256，一个字符（汉字还是英文存疑）占用 256 个宽度，因此要将字符串长度乘 256 的到最终宽度。但是最终的效果是列宽明显长于内容宽度，怀疑不是所有字符都占用256个宽度</p>
<h3 id="空元素处理"><a href="#空元素处理" class="headerlink" title="空元素处理"></a>空元素处理</h3><p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231128223733210.png" alt="image-20231128223732560"></p>
<p>对于缺失元素，通过判断其是否缺失来赋值其内容或空字符串。</p>
<h1 id="Selenium-Library"><a href="#Selenium-Library" class="headerlink" title="Selenium Library"></a>Selenium Library</h1><p>在爬虫的第一步，即通过浏览器控制台 / burpsuite 抓包获取 headers，这也是很简单的一步，因此也有现成的库可以使用，不要让一窍不通的用户自己获取。</p>
<p>Edeg 官方教程：<a target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/microsoft-edge/webdriver-chromium/?tabs=python">https://learn.microsoft.com/en-us/microsoft-edge/webdriver-chromium/?tabs=python</a></p>
<p>msedgedrive 在 macos 上存在一些问题（估计是 Microsoft 看不惯 Apple，一直没修），需要手动指定 Unix 可执行文件（Unix 无拓展名），且需要指定 capabilities 为空或者 capabilities.platformName=”mac”，否则就会自动认为是在环境变量下搜索 exe 文件，且平台为 Windows。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231129170915760.png" alt="image-20231129170915066"></p>
<p><strong>更新. Selenium 4 对 Edge 的支持大幅提升，集成了 msedge-selenium-tools ，不需要再这么做了。</strong></p>
<p>控制台审查元素功能可以快速获取元素信息，鼠标放在元素上时可以显示 CSS Selector 所需的值。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231129174031056.png" alt="image-20231129174030451"></p>
<p>剩下的见 ipynb。</p>
<h1 id="Demo-3-Bilibili-所有-TOEFL-视频-amp-Phantomjs-Library"><a href="#Demo-3-Bilibili-所有-TOEFL-视频-amp-Phantomjs-Library" class="headerlink" title="Demo 3: Bilibili 所有 TOEFL 视频 &amp; Phantomjs Library"></a>Demo 3: Bilibili 所有 TOEFL 视频 &amp; Phantomjs Library</h1><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>按照教程这里应该使用 Phantomjs Library 来实现无前端无感爬取，但这个方法已被 selenium 废弃，取而代之的是其他浏览器的 headless 模式，为了使用 Edge 的 headless 模式，需要升级到 Selenium 4。</p>
<p>升级注意事项：<a target="_blank" rel="noopener" href="https://www.selenium.dev/documentation/webdriver/troubleshooting/upgrade_to_selenium_4/">Upgrade to Selenium 4 | Selenium</a></p>
<p>语法没什么大变化，但是对 Edge 的支持大幅提升，且可以兼容 Selenium 3 的代码。</p>
<h2 id="分析-2"><a href="#分析-2" class="headerlink" title="分析"></a>分析</h2><p>目标 url：<a target="_blank" rel="noopener" href="https://search.bilibili.com">https://search.bilibili.com</a></p>
<p>1. 元素信息</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231130140911931.png" alt="image-20231130140911234"></p>
<p>可直接复制其 XPath，通过 <code>By.XPATH</code> 查找元素。复制 CSS Selector 同理。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231130143909793.png" alt="image-20231130143909159"></p>
<p>2. 通过 GET Request 参数 <code>?keyword=TOEFL&amp;page=3&amp;o=60</code>，<code>keyword</code> 和 <code>page</code> 指定页数，<code>o</code> 由 <code>page</code> 确定，不是自由参数。</p>
<p>3. 所需信息</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231130142344407.png" alt="image-20231130142343774"></p>
<p>名称、链接、播放量、弹幕量、up主、投稿时间</p>
<p>代码定位自寻</p>
<p>因为是模拟手动点击，因此也不需要 headers。</p>
<h2 id="代码实现-3"><a href="#代码实现-3" class="headerlink" title="代码实现"></a>代码实现</h2><p>Selenium Waits技术：<a target="_blank" rel="noopener" href="https://selenium-python-zh.readthedocs.io/en/latest/waits.html">5. 等待页面加载完成(Waits) — Selenium-Python中文文档 2 documentation (selenium-python-zh.readthedocs.io)</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.by <span class="keyword">import</span> By</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.edge.options <span class="keyword">import</span> Options</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support.ui <span class="keyword">import</span> WebDriverWait</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.support <span class="keyword">import</span> expected_conditions <span class="keyword">as</span> EC</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_html</span>(<span class="params">curr_page, html</span>):</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    <span class="built_in">list</span> = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;video-list row&#x27;</span>).find_all(<span class="string">&quot;div&quot;</span>, class_=<span class="string">&quot;bili-video-card&quot;</span>, limit=<span class="number">25</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> <span class="built_in">list</span>:</span><br><span class="line">        title = item.find(<span class="string">&quot;h3&quot;</span>, class_=<span class="string">&quot;bili-video-card__info--tit&quot;</span>).get(<span class="string">&quot;title&quot;</span>)</span><br><span class="line">        view_counts = item.find_all(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;bili-video-card__stats--item&quot;</span>)[<span class="number">0</span>].find(<span class="string">&quot;span&quot;</span>).text</span><br><span class="line">        danmu_counts = item.find_all(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;bili-video-card__stats--item&quot;</span>)[<span class="number">1</span>].find(<span class="string">&quot;span&quot;</span>).text</span><br><span class="line">        author = item.find(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;bili-video-card__info--author&quot;</span>).text</span><br><span class="line">        date = item.find(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;bili-video-card__info--date&quot;</span>).text[<span class="number">3</span>:]</span><br><span class="line">        <span class="built_in">print</span>(title)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># yield [title, view_counts, danmu_counts, author, date]</span></span><br><span class="line">        <span class="keyword">yield</span> [curr_page, title, view_counts, danmu_counts, author, date]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">options = Options()</span><br><span class="line">options.add_argument(<span class="string">&quot;headless&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># driver = webdriver.Edge(executable_path=&#x27;/Users/wanpengxu/EnvPATH/msedgedriver&#x27;, capabilities=&#123;&#125;) # Selenium 3</span></span><br><span class="line"><span class="comment"># driver = webdriver.PhantomJS()    # has been deprecated</span></span><br><span class="line"></span><br><span class="line">driver = webdriver.Edge(options = options)  <span class="comment"># Selenium 4</span></span><br><span class="line"></span><br><span class="line">driver.get(<span class="string">&quot;https://search.bilibili.com/&quot;</span>)</span><br><span class="line"></span><br><span class="line">wait = WebDriverWait(driver, <span class="number">10</span>)</span><br><span class="line">input_elem = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">&quot;input.search-input-el&quot;</span>)))</span><br><span class="line">search_elem = wait.until(EC.element_to_be_clickable((By.XPATH, <span class="string">&#x27;//button[@class=&quot;vui_button vui_button--blue vui_button--lg search-button&quot;]&#x27;</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;TOEFL_videos.csv&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    csv_writer = csv.writer(f)</span><br><span class="line">    <span class="comment"># csv_writer.writerow([&quot;Title&quot;, &quot;View Counts&quot;, &quot;Danmu Counts&quot;, &quot;Author&quot;, &quot;Date&quot;])</span></span><br><span class="line">    csv_writer.writerow([<span class="string">&quot;Page&quot;</span>, <span class="string">&quot;Title&quot;</span>, <span class="string">&quot;View Counts&quot;</span>, <span class="string">&quot;Danmu Counts&quot;</span>, <span class="string">&quot;Author&quot;</span>, <span class="string">&quot;Date&quot;</span>])</span><br><span class="line"></span><br><span class="line">    curr_page = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line">        <span class="built_in">print</span>(curr_page)</span><br><span class="line">        <span class="keyword">if</span> curr_page == <span class="number">1</span>:</span><br><span class="line">            input_elem.send_keys(<span class="string">&quot;TOEFL&quot;</span>)</span><br><span class="line">            search_elem.click()</span><br><span class="line"></span><br><span class="line">            lastpage_elem = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">&quot;div.vui_pagenation--btns &gt; button:nth-last-child(2)&quot;</span>)))</span><br><span class="line">            total_page = <span class="built_in">int</span>(lastpage_elem.text)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            next_page_button = wait.until(EC.element_to_be_clickable((By.XPATH, <span class="string">&#x27;//button[@class=&quot;vui_button vui_pagenation--btn vui_pagenation--btn-side&quot; and contains(text(), &quot;下一页&quot;)]&#x27;</span>)))</span><br><span class="line">            next_page_button.click()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 稳健性代码，确保全部加载出来后再爬下一页</span></span><br><span class="line">        time.sleep(<span class="number">3</span>)</span><br><span class="line">        <span class="comment"># 判断页面指定元素和元素内指定文字加载出后再获取源码，否则会重复爬取同一页</span></span><br><span class="line">        wait.until(EC.presence_of_element_located((By.XPATH, <span class="string">&#x27;//div[@class=&quot;video-list row&quot;]&#x27;</span>)))</span><br><span class="line">        wait.until(EC.text_to_be_present_in_element((By.CSS_SELECTOR, <span class="string">&#x27;.vui_button.vui_button--active.vui_button--active-blue.vui_button--no-transition.vui_pagenation--btn.vui_pagenation--btn-num&#x27;</span>), <span class="built_in">str</span>(curr_page)))</span><br><span class="line">        html = driver.page_source</span><br><span class="line">        items = parse_html(curr_page, html)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            csv_writer.writerow(item)</span><br><span class="line"></span><br><span class="line">        curr_page += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> curr_page == total_page + <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">driver.quit()</span><br></pre></td></tr></table></figure>
<p>爬取结果</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231201105912391.png" alt="image-20231201105911634"></p>
<h2 id="实现细节-3"><a href="#实现细节-3" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="稳健地获取元素"><a href="#稳健地获取元素" class="headerlink" title="稳健地获取元素"></a>稳健地获取元素</h3><p>网站可能会更改元素层级，但其他信息一般不会更改。因此，尽量不要用控制台复制的 XPath 绝对路径，可以用元素种类、类、id、元素内文本等信息直接指定元素。</p>
<p><code>next_page_button = wait.until(EC.element_to_be_clickable((By.XPATH, &#39;//button[@class=&quot;vui_button vui_pagenation--btn vui_pagenation--btn-side&quot; and contains(text(), &quot;下一页&quot;)]&#39;)))</code></p>
<h3 id="稳健地爬取"><a href="#稳健地爬取" class="headerlink" title="稳健地爬取"></a>稳健地爬取</h3><p>如果每页等待时间过短，程序会重复抓取同一页，最简单的办法是直接 <code>time.sleep(3)</code>，要比 <code>Waits</code> 简单稳健。</p>
<p>程序的整体完成时间在一天左右，主要困难在于选择元素和稳健选择元素。</p>
<h1 id="Parse-Json-data"><a href="#Parse-Json-data" class="headerlink" title="Parse Json data"></a>Parse Json data</h1><p>教程在这里以微信网页版为例，截止目前（20231201）微信网页版已停用，因此跳过。</p>
<p>事实上 Demo1 的 json 版已经能很好地解析 / 写入 json 数据了。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231201110800356.png" alt="image-20231201110759732"></p>
<p>更多见 Demo 8</p>
<h1 id="Multi-Threading-amp-Thread-Pool"><a href="#Multi-Threading-amp-Thread-Pool" class="headerlink" title="Multi-Threading &amp; Thread Pool"></a>Multi-Threading &amp; Thread Pool</h1><p>常用的多线程模块：<code>threading</code>、<code>Queue</code></p>
<p>我觉得线程可以理解为隧道，在开车过程中挖隧道和炸隧道都是比较耗资源的，所以最好在 python 进程启动时就创建好有很多线程的线程组（大型隧道组），也不销毁，用的时候就给它指定任务。</p>
<p>这个比较重要，从ipynb复制过来了。</p>
<h2 id="单线程"><a href="#单线程" class="headerlink" title="单线程"></a>单线程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">moyu</span>(<span class="params">name, delay, counter</span>):</span><br><span class="line">    <span class="keyword">while</span> counter:</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> 开始摸鱼 <span class="subst">&#123;time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, time.localtime())&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        counter -= <span class="number">1</span></span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    moyu(<span class="string">&#x27;WanpengXu&#x27;</span>,<span class="number">1</span>,<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:46</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:47</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:48</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:49</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:50</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:51</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:52</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:53</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:54</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:55</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:56</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:57</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:58</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:07:59</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:08:00</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:08:01</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:08:02</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:08:03</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:08:04</span><br><span class="line">WanpengXu 开始摸鱼 2023-12-02 10:08:05</span><br></pre></td></tr></table></figure>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个线程子类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyThread</span>(threading.Thread):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,thread_ID, name, delay, counter</span>):</span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.thread_ID = thread_ID</span><br><span class="line">        self.name = name</span><br><span class="line">        self.delay = delay</span><br><span class="line">        self.counter = counter</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;开始线程：&quot;</span> + self.name)</span><br><span class="line">        moyu(self.name, self.delay, self.counter)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;退出线程：&quot;</span> + self.name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">moyu</span>(<span class="params">thread_name, delay, counter</span>):</span><br><span class="line">        <span class="keyword">while</span> counter:</span><br><span class="line">            time.sleep(delay)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;thread_name&#125;</span> 开始摸鱼 <span class="subst">&#123;time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, time.localtime())&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            counter -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个 Python 进程包含一个主线程</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建新线程 </span></span><br><span class="line">    <span class="comment"># 小明每1s摸一次鱼，任务是摸完10条鱼</span></span><br><span class="line">    thread1 = MyThread(<span class="number">1</span>, <span class="string">&quot;小明&quot;</span>, <span class="number">1</span>, <span class="number">10</span>) </span><br><span class="line">    <span class="comment"># 小红每2s摸一次鱼，任务是摸完10条鱼</span></span><br><span class="line">    thread2 = MyThread(<span class="number">2</span>, <span class="string">&quot;小红&quot;</span>, <span class="number">2</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开启新线程 </span></span><br><span class="line">    thread1.start() </span><br><span class="line">    thread2.start() </span><br><span class="line"></span><br><span class="line">    <span class="comment"># 主线程阻塞，等待至两个子线程中止 </span></span><br><span class="line">    thread1.join() </span><br><span class="line">    thread2.join()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 继续主线程，主线程结束</span></span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&quot;退出主线程&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 奇数秒：小明摸，偶数秒：俩人同时摸（vice versa）</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">开始线程：小明</span><br><span class="line">开始线程：小红</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:45</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:10:46</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:46</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:47</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:10:48</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:48</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:49</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:10:50</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:50</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:51</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:10:52</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:52</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:53</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:10:54</span><br><span class="line">小明 开始摸鱼 2023-12-02 10:10:54</span><br><span class="line">退出线程：小明</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:10:56</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:10:58</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:11:00</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:11:02</span><br><span class="line">小红 开始摸鱼 2023-12-02 10:11:04</span><br><span class="line">退出线程：小红</span><br><span class="line">退出主线程</span><br></pre></td></tr></table></figure>
<h2 id="用-ThreadPoolExecutor-管理多线程"><a href="#用-ThreadPoolExecutor-管理多线程" class="headerlink" title="用 ThreadPoolExecutor 管理多线程"></a>用 ThreadPoolExecutor 管理多线程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">moyu</span>(<span class="params">name, delay, counter, lock</span>):</span><br><span class="line">    <span class="keyword">with</span> lock:</span><br><span class="line">        <span class="built_in">print</span>(threading.current_thread().name)</span><br><span class="line">    <span class="keyword">while</span> counter:</span><br><span class="line">        time.sleep(delay)</span><br><span class="line">        <span class="comment"># 加锁，用于确保 print 操作的原子性，从而避免多个线程同时打印导致的混乱。</span></span><br><span class="line">        <span class="keyword">with</span> lock:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span> 开始摸鱼 <span class="subst">&#123;time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, time.localtime())&#125;</span>&#x27;</span>)</span><br><span class="line">        counter -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pool = ThreadPoolExecutor(max_workers=<span class="number">20</span>)</span><br><span class="line">    lock = threading.Lock()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="comment"># pool.submit(moyu(f&#x27;WanpengXu&#123;i&#125;&#x27;, 1, 3))</span></span><br><span class="line">        pool.submit(moyu, <span class="string">f&#x27;WanpengXu<span class="subst">&#123;i&#125;</span>&#x27;</span>, <span class="number">1</span>, <span class="number">4</span>, lock)  <span class="comment"># 一定是要提交一个待执行任务（函数和参数），而不是主函数创建的任务</span></span><br><span class="line"></span><br><span class="line">    pool.shutdown(wait=<span class="literal">True</span>)    <span class="comment"># pool 没有 join 方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每秒钟5个人摸鱼</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">ThreadPoolExecutor-0_0</span><br><span class="line">ThreadPoolExecutor-0_2</span><br><span class="line">ThreadPoolExecutor-0_1</span><br><span class="line">ThreadPoolExecutor-0_3</span><br><span class="line">ThreadPoolExecutor-0_4</span><br><span class="line">WanpengXu1 开始摸鱼 2023-12-02 10:17:27</span><br><span class="line">WanpengXu4 开始摸鱼 2023-12-02 10:17:27</span><br><span class="line">WanpengXu0 开始摸鱼 2023-12-02 10:17:27</span><br><span class="line">WanpengXu2 开始摸鱼 2023-12-02 10:17:27</span><br><span class="line">WanpengXu3 开始摸鱼 2023-12-02 10:17:27</span><br><span class="line">WanpengXu1 开始摸鱼 2023-12-02 10:17:28</span><br><span class="line">WanpengXu4 开始摸鱼 2023-12-02 10:17:28</span><br><span class="line">WanpengXu0 开始摸鱼 2023-12-02 10:17:28</span><br><span class="line">WanpengXu3 开始摸鱼 2023-12-02 10:17:28</span><br><span class="line">WanpengXu2 开始摸鱼 2023-12-02 10:17:28</span><br><span class="line">WanpengXu0 开始摸鱼 2023-12-02 10:17:29</span><br><span class="line">WanpengXu1 开始摸鱼 2023-12-02 10:17:29</span><br><span class="line">WanpengXu2 开始摸鱼 2023-12-02 10:17:29</span><br><span class="line">WanpengXu4 开始摸鱼 2023-12-02 10:17:29</span><br><span class="line">WanpengXu3 开始摸鱼 2023-12-02 10:17:29</span><br><span class="line">WanpengXu0 开始摸鱼 2023-12-02 10:17:30</span><br><span class="line">WanpengXu2 开始摸鱼 2023-12-02 10:17:30</span><br><span class="line">WanpengXu4 开始摸鱼 2023-12-02 10:17:30</span><br><span class="line">WanpengXu1 开始摸鱼 2023-12-02 10:17:30</span><br><span class="line">WanpengXu3 开始摸鱼 2023-12-02 10:17:30</span><br></pre></td></tr></table></figure>
<h2 id="用-Queue-管理多线程"><a href="#用-Queue-管理多线程" class="headerlink" title="用 Queue 管理多线程"></a>用 Queue 管理多线程</h2><p>这个示例的逻辑和上面的不太一样，是5个人<strong>一共</strong>20个任务，每个任务只摸1条鱼；上面的是5个人<strong>每人</strong>1个任务，每个任务摸4条鱼。结果都是每秒钟5个人摸鱼，4s末时任务结束。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomThread</span>(threading.Thread):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, queue, delay, lock</span>):  <span class="comment"># 让线程可以读队列中的任务</span></span><br><span class="line">        threading.Thread.__init__(self)</span><br><span class="line">        self.queue = queue</span><br><span class="line">        self.delay = delay</span><br><span class="line">        self.lock = lock</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            task = self.queue.get() <span class="comment"># 和pop一样，取出并删除数据</span></span><br><span class="line">            task(self.delay, self.lock)</span><br><span class="line">            self.queue.task_done()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">moyu</span>(<span class="params">delay, lock</span>):</span><br><span class="line">    time.sleep(delay)</span><br><span class="line">    <span class="keyword">with</span> lock:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;threading.current_thread().name&#125;</span> 开始摸鱼 <span class="subst">&#123;time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>, time.localtime())&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">queue_pool</span>():</span><br><span class="line">    queue = Queue(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5个线程，20任务横着推进队列，每5个同时从上面出来，每次需要1s完成</span></span><br><span class="line">    lock = threading.Lock()</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(queue.maxsize):</span><br><span class="line">        t = CustomThread(queue, <span class="number">1</span>, lock)</span><br><span class="line">        t.daemon = <span class="literal">True</span></span><br><span class="line">        t.start()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">        queue.put(moyu)</span><br><span class="line">    queue.join()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    queue_pool()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每秒钟5个人摸鱼</span></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Thread-4 开始摸鱼 2023-12-02 10:20:20</span><br><span class="line">Thread-8 开始摸鱼 2023-12-02 10:20:20</span><br><span class="line">Thread-5 开始摸鱼 2023-12-02 10:20:20</span><br><span class="line">Thread-7 开始摸鱼 2023-12-02 10:20:20</span><br><span class="line">Thread-6 开始摸鱼 2023-12-02 10:20:20</span><br><span class="line">Thread-8 开始摸鱼 2023-12-02 10:20:21</span><br><span class="line">Thread-7 开始摸鱼 2023-12-02 10:20:21</span><br><span class="line">Thread-6 开始摸鱼 2023-12-02 10:20:21</span><br><span class="line">Thread-4 开始摸鱼 2023-12-02 10:20:21</span><br><span class="line">Thread-5 开始摸鱼 2023-12-02 10:20:21</span><br><span class="line">Thread-8 开始摸鱼 2023-12-02 10:20:22</span><br><span class="line">Thread-7 开始摸鱼 2023-12-02 10:20:22</span><br><span class="line">Thread-5 开始摸鱼 2023-12-02 10:20:22</span><br><span class="line">Thread-4 开始摸鱼 2023-12-02 10:20:22</span><br><span class="line">Thread-6 开始摸鱼 2023-12-02 10:20:22</span><br><span class="line">Thread-5 开始摸鱼 2023-12-02 10:20:23</span><br><span class="line">Thread-6 开始摸鱼 2023-12-02 10:20:23</span><br><span class="line">Thread-8 开始摸鱼 2023-12-02 10:20:23</span><br><span class="line">Thread-4 开始摸鱼 2023-12-02 10:20:23</span><br><span class="line">Thread-7 开始摸鱼 2023-12-02 10:20:23</span><br></pre></td></tr></table></figure>
<h1 id="DEMO-4-每日妹子图"><a href="#DEMO-4-每日妹子图" class="headerlink" title="DEMO 4: 每日妹子图"></a>DEMO 4: 每日妹子图</h1><h2 id="分析-3"><a href="#分析-3" class="headerlink" title="分析"></a>分析</h2><p>目标url：<a target="_blank" rel="noopener" href="https://meizi8.com/">https://meizi8.com/</a></p>
<p>1. 通过 url 地址<code>https://meizi8.com/page/n</code> 翻到第 n 页</p>
<p>2. 每页有 16 个帖子（预览图），每个帖子内有 1~10 张不等图片，page -&gt; post -&gt; picture</p>
<p>3. 所需信息</p>
<p>帖子内的所有图片</p>
<h2 id="程序思路-2"><a href="#程序思路-2" class="headerlink" title="程序思路"></a>程序思路</h2><p>先循环构造每页的地址，设计一个函数从每页中获取16个帖子的地址，再设计一个函数下载每个帖子内的所有图片，可以创建 n 个线程每次爬取 n 个帖子内的所有图片。</p>
<p>除了多线程那三行代码没什么新技术。</p>
<h2 id="代码实现-4"><a href="#代码实现-4" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ProcessPoolExecutor</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;Cookie&quot;</span>: <span class="string">&#x27;__51vcke__Js6m73nB7LGdoohB=ab53e2f7-6d63-552c-b3cb-c8ba9f968f03; __51vuft__Js6m73nB7LGdoohB=1701484179543; __51uvsct__Js6m73nB7LGdoohB=2; __vtins__Js6m73nB7LGdoohB=%7B%22sid%22%3A%20%22aa316a0d-e89c-5917-b4f7-a179bdfec266%22%2C%20%22vd%22%3A%2022%2C%20%22stt%22%3A%203514223%2C%20%22dr%22%3A%20153537%2C%20%22expires%22%3A%201701527611751%2C%20%22ct%22%3A%201701525811751%7D&#x27;</span>,</span><br><span class="line">    <span class="string">&quot;Referer&quot;</span>:<span class="string">&#x27;https://meizi8.com/&#x27;</span>,</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request_page</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> res.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_post_urls_from_page</span>(<span class="params">html</span>):</span><br><span class="line">    post_urls_per_page = []</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    posts = soup.find(<span class="string">&quot;div&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;masonry&quot;</span>, <span class="string">&quot;id&quot;</span>: <span class="string">&quot;masonry&quot;</span>&#125;).find_all(<span class="string">&quot;article&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;masonry-item&quot;</span>&#125;)</span><br><span class="line">    <span class="keyword">for</span> post <span class="keyword">in</span> posts:</span><br><span class="line">        post_url = post.find(<span class="string">&quot;a&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;entry-thumbnail&quot;</span>&#125;).get(<span class="string">&quot;href&quot;</span>)</span><br><span class="line">        post_urls_per_page.append(post_url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> post_urls_per_page</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download_pics_from_post</span>(<span class="params">url</span>):</span><br><span class="line">    post_html = request_page(url)</span><br><span class="line">    soup = BeautifulSoup(post_html, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line"></span><br><span class="line">    title = soup.find(<span class="string">&quot;h1&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;entry-title&quot;</span>&#125;).string</span><br><span class="line">    pic_urls = []</span><br><span class="line">    <span class="comment"># 有的post最后一项是引导链接，不要那个</span></span><br><span class="line">    pic_items = [item <span class="keyword">for</span> item <span class="keyword">in</span> soup.find(<span class="string">&quot;div&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;entry themeform&quot;</span>&#125;).find_all(<span class="string">&#x27;p&#x27;</span>) <span class="keyword">if</span> item.get(<span class="string">&quot;style&quot;</span>) == <span class="literal">None</span>]</span><br><span class="line">    <span class="keyword">for</span> pic_item <span class="keyword">in</span> pic_items:</span><br><span class="line">        pic_url = pic_item.find(<span class="string">&quot;img&quot;</span>).get(<span class="string">&quot;src&quot;</span>)</span><br><span class="line">        pic_urls.append(pic_url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">f&quot;<span class="subst">&#123;title&#125;</span>&quot;</span>):</span><br><span class="line">        os.mkdir(<span class="string">f&quot;<span class="subst">&#123;title&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 多线程下切换目录会出错</span></span><br><span class="line">    <span class="comment"># os.chdir(f&quot;&#123;title&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">for</span> pic_url <span class="keyword">in</span> pic_urls:</span><br><span class="line">        filename = <span class="string">f&#x27;<span class="subst">&#123;title&#125;</span>/<span class="subst">&#123;pic_url.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]&#125;</span>&#x27;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;multiprocessing.current_process().name&#125;</span> is downloading <span class="subst">&#123;pic_url&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># print(filename)</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            img = requests.get(pic_url, headers=headers).content</span><br><span class="line">            f.write(img)</span><br><span class="line">    <span class="comment"># os.chdir(&quot;..&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;meizi8&quot;</span>):</span><br><span class="line">        os.mkdir(<span class="string">&quot;meizi8&quot;</span>)</span><br><span class="line">    os.chdir(<span class="string">&quot;meizi8&quot;</span>)</span><br><span class="line"></span><br><span class="line">    post_urls = []</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">2</span>+<span class="number">1</span>):</span><br><span class="line">        page_url = <span class="string">f&quot;https://meizi8.com/page/<span class="subst">&#123;page&#125;</span>&quot;</span></span><br><span class="line">        page_html = request_page(page_url)</span><br><span class="line">        post_urls.extend(get_post_urls_from_page(page_html))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计时</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 单主线程</span></span><br><span class="line">    <span class="comment"># for post_url in post_urls:</span></span><br><span class="line">    <span class="comment">#     download_pics_from_post(post_url)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多线程 (GIL锁，反而会慢)</span></span><br><span class="line">    <span class="comment"># with ThreadPoolExecutor(max_workers=8) as exector:</span></span><br><span class="line">    <span class="comment">#     for post_url in post_urls:</span></span><br><span class="line">    <span class="comment">#         exector.submit(download_pics_from_post, post_url)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多进程</span></span><br><span class="line">    <span class="keyword">with</span> ProcessPoolExecutor(max_workers=<span class="number">16</span>) <span class="keyword">as</span> exector:</span><br><span class="line">        <span class="keyword">for</span> post_url <span class="keyword">in</span> post_urls:</span><br><span class="line">            exector.submit(download_pics_from_post, post_url)</span><br><span class="line"></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    elapsed_time = end_time - start_time</span><br><span class="line">    <span class="built_in">print</span>(elapsed_time)</span><br></pre></td></tr></table></figure>
<p>单主线程时间：323.1215920448303</p>
<p>4线程时间：180.1571547985077</p>
<p>8线程时间：215.17093300819397</p>
<p>4进程时间：266.51773381233215</p>
<p>8进程时间：198.45511484146118</p>
<p>16进程时间：175.14416122436523</p>
<h2 id="实现细节-4"><a href="#实现细节-4" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="404解决"><a href="#404解决" class="headerlink" title="404解决"></a>404解决</h3><p>加Refer</p>
<h3 id="筛选不包含某属性的元素"><a href="#筛选不包含某属性的元素" class="headerlink" title="筛选不包含某属性的元素"></a>筛选不包含某属性的元素</h3><p>对于这个 demo，部分 post 最后一项元素是引导链接，所以不能全部 <code>`[:-1]</code>。它和其他元素的区别在于它多了一个属性 <code>style</code>，因此可以利用这点筛去它，由于 chatgpt 给的 <code>:not()</code> 不能用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pic_items = soup.find(<span class="string">&quot;div&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;entry themeform&quot;</span>&#125;).find_all(<span class="string">&#x27;p:not([style=&quot;text-align: center;&quot;])&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>因此使用了简单的 <code>get()</code> 配合列表解析实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pic_items = [item <span class="keyword">for</span> item <span class="keyword">in</span> soup.find(<span class="string">&quot;div&quot;</span>, attrs=&#123;<span class="string">&quot;class&quot;</span>: <span class="string">&quot;entry themeform&quot;</span>&#125;).find_all(<span class="string">&#x27;p&#x27;</span>) <span class="keyword">if</span> item.get(<span class="string">&quot;style&quot;</span>) == <span class="literal">None</span>]</span><br></pre></td></tr></table></figure>
<h3 id="GIL锁"><a href="#GIL锁" class="headerlink" title="GIL锁"></a>GIL锁</h3><p>代码执行速度瓶颈是网络请求时，Python 的全局解释器锁 (GIL) 会阻止多线程并行执行 Python 字节码。</p>
<p>因此这种情况适合使用多进程。</p>
<h1 id="Multi-Processing-amp-Process-Pool"><a href="#Multi-Processing-amp-Process-Pool" class="headerlink" title="Multi-Processing &amp; Process Pool"></a>Multi-Processing &amp; Process Pool</h1><h2 id="创建进程"><a href="#创建进程" class="headerlink" title="创建进程"></a>创建进程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">from</span> multiprocessing_func <span class="keyword">import</span> func</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    p = Process(target=func, args=(<span class="string">&#x27;WanpengXu&#x27;</span>, ), name=<span class="string">&quot;P001&quot;</span>)  <span class="comment"># 额外的,用于标识元组</span></span><br><span class="line">    p.start()</span><br><span class="line">    p.join()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello, WanpengXu! I am P001.</span><br></pre></td></tr></table></figure>
<h2 id="用-Pool-或-ProcessPoolExecutor-管理多进程"><a href="#用-Pool-或-ProcessPoolExecutor-管理多进程" class="headerlink" title="用 Pool 或 ProcessPoolExecutor 管理多进程"></a>用 Pool 或 ProcessPoolExecutor 管理多进程</h2><p>Pool 和 ProcessPoolExecutor 不太一样</p>
<p><code>Pool.map</code> 自动提交任务，同步处理所有任务</p>
<p><code>ProcessPoolExecutor.submit</code> 手动提交任务，异步处理每个任务</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">from</span> multiprocessing_func <span class="keyword">import</span> sqrt_func</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ProcessPoolExecutor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进程的启动、管理、通信有开销，数据规模小时单进程更高效</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">    <span class="comment"># data = list(range(1, 500000000))  # 此时几乎在一个数量级上，估计只有数量级为小时的情况多进程才能更快</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 单进程</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    result = [x ** <span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> data]</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="built_in">print</span>(end_time - start_time)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 多进程</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="comment"># 5个元素的平方任务被map到5个进程分别进行</span></span><br><span class="line">    <span class="keyword">with</span> Pool(processes=<span class="number">5</span>) <span class="keyword">as</span> p:</span><br><span class="line">        result = p.<span class="built_in">map</span>(sqrt_func, data) <span class="comment"># 同步处理所有任务</span></span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="built_in">print</span>(end_time - start_time)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多进程</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    <span class="comment"># 5个元素的平方任务被map到5个进程分别进行</span></span><br><span class="line">    <span class="keyword">with</span> ProcessPoolExecutor(max_workers=<span class="number">5</span>) <span class="keyword">as</span> executor:</span><br><span class="line">        futures = [executor.submit(sqrt_func, x) <span class="keyword">for</span> x <span class="keyword">in</span> data] <span class="comment"># 异步处理单个任务</span></span><br><span class="line">    result = [future.result() <span class="keyword">for</span> future <span class="keyword">in</span> futures]</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="built_in">print</span>(end_time - start_time)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[1, 4, 9, 16, 25, 36]</span><br><span class="line">2.574920654296875e-05</span><br><span class="line">[1, 4, 9, 16, 25, 36]</span><br><span class="line">0.05546903610229492</span><br><span class="line">[1, 4, 9, 16, 25, 36]</span><br><span class="line">0.07867026329040527</span><br></pre></td></tr></table></figure>
<p>工具函数需要单独放在另一个包中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">name</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;hello, <span class="subst">&#123;name&#125;</span>! I am <span class="subst">&#123;multiprocessing.current_process().name&#125;</span>.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sqrt_func</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x * x</span><br></pre></td></tr></table></figure>
<h1 id="DEMO-5-豆瓣-Top-250-电影-进阶"><a href="#DEMO-5-豆瓣-Top-250-电影-进阶" class="headerlink" title="DEMO 5: 豆瓣 Top 250 电影 进阶"></a>DEMO 5: 豆瓣 Top 250 电影 进阶</h1><h2 id="代码实现-5"><a href="#代码实现-5" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> xlwt</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request_url</span>(<span class="params">url</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Cookie&quot;</span>: <span class="string">&#x27;bid=r5NyipyS844; _pk_id.100001.4cf6=8d2637ab28beb521.1698656720.; dbcl2=&quot;220842516:kaSCAN2Yw5c&quot;; __utmz=30149280.1701170775.3.3.utmcsr=open.weixin.qq.com|utmccn=(referral)|utmcmd=referral|utmcct=/; __utmz=223695111.1701170775.2.2.utmcsr=open.weixin.qq.com|utmccn=(referral)|utmcmd=referral|utmcct=/; push_noty_num=0; push_doumail_num=0; __yadk_uid=bdyEdGw5LBo9dXxUEYdWEygyv1MkelW3; ll=&quot;118159&quot;; _vwo_uuid_v2=D3AA59641F59DCBAC831E95557CC131F7|984fdef9e1fa1ff456b997f6b8bb588b; ck=u7Tj; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1701606524%2C%22https%3A%2F%2Fopen.weixin.qq.com%2F%22%5D; _pk_ses.100001.4cf6=1; ap_v=0,6.0; __utma=30149280.1380904537.1698110791.1701180703.1701606525.6; __utmb=30149280.0.10.1701606525; __utmc=30149280; __utma=223695111.603104195.1698656720.1701180703.1701606525.5; __utmb=223695111.0.10.1701606525; __utmc=223695111&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> res.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_html</span>(<span class="params">html</span>):</span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line">    <span class="built_in">list</span> = soup.find(<span class="string">&quot;ol&quot;</span>, class_=<span class="string">&quot;grid_view&quot;</span>).find_all(<span class="string">&quot;li&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> <span class="built_in">list</span>:</span><br><span class="line">        rank = li.find(<span class="string">&quot;em&quot;</span>, class_=<span class="string">&quot;&quot;</span>).string</span><br><span class="line">        img = li.find(<span class="string">&#x27;a&#x27;</span>).find(<span class="string">&quot;img&quot;</span>).get(<span class="string">&quot;src&quot;</span>)</span><br><span class="line">        title = li.find(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;title&quot;</span>).string</span><br><span class="line">        author, <span class="built_in">type</span> = li.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&quot;&quot;</span>).text.strip().split(<span class="string">&quot;\n                            &quot;</span>)</span><br><span class="line">        score = li.find(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;rating_num&quot;</span>).string</span><br><span class="line">        <span class="comment"># review_count = li.find(&quot;div&quot;, class_=&quot;star&quot;).find(&quot;span&quot;, string=&quot;人评价&quot;).get_previous_sibling().string</span></span><br><span class="line">        review_count = li.find(<span class="string">&quot;div&quot;</span>, class_=<span class="string">&quot;star&quot;</span>).find_all(<span class="string">&quot;span&quot;</span>)[-<span class="number">1</span>].string</span><br><span class="line">        <span class="built_in">print</span>(rank, title)</span><br><span class="line">        best_comment_elem = li.find(<span class="string">&quot;span&quot;</span>, class_=<span class="string">&quot;inq&quot;</span>)</span><br><span class="line">        best_comment = best_comment_elem.string <span class="keyword">if</span> best_comment_elem != <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> [rank, img, title, author, <span class="built_in">type</span>, score, review_count, best_comment]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_to_csv</span>(<span class="params">file_path, item</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        csv_writer = csv.writer(f)</span><br><span class="line">        csv_writer.writerow(item)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crawl_url</span>(<span class="params">args</span>):</span><br><span class="line">    file_path, url = args</span><br><span class="line">    html = request_url(url)</span><br><span class="line">    items = parse_html(html)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        write_to_csv(file_path, item)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    file_path = <span class="string">&quot;top250_movies_2.csv&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        csv_writer = csv.writer(f)</span><br><span class="line">        csv_writer.writerow([<span class="string">&#x27;Rank&#x27;</span>, <span class="string">&#x27;Image&#x27;</span>, <span class="string">&#x27;Title&#x27;</span>, <span class="string">&#x27;Author&#x27;</span>, <span class="string">&#x27;Type&#x27;</span>, <span class="string">&#x27;Score&#x27;</span>, <span class="string">&#x27;Review Count&#x27;</span>, <span class="string">&#x27;Best Comment&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    urls = [<span class="string">f&quot;https://movie.douban.com/top250?start=<span class="subst">&#123;start&#125;</span>&quot;</span> <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">225</span>+<span class="number">1</span>, <span class="number">25</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> multiprocessing.Pool(multiprocessing.cpu_count()) <span class="keyword">as</span> pool:</span><br><span class="line">        pool.<span class="built_in">map</span>(crawl_url, [(file_path, url) <span class="keyword">for</span> url <span class="keyword">in</span> urls])</span><br></pre></td></tr></table></figure>
<h2 id="实现细节-5"><a href="#实现细节-5" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="并发写入"><a href="#并发写入" class="headerlink" title="并发写入"></a>并发写入</h3><p>多进程并发写入文件很难，干脆用csv，每次写入都打开文件、新建句柄，因为传入writer句柄也不太容易</p>
<h3 id="保证顺序"><a href="#保证顺序" class="headerlink" title="保证顺序"></a>保证顺序</h3><p>要保证顺序就更难，如果爬取内容本身有排名，那就乱序写入吧，爬好之后再排</p>
<h1 id="Proxy-amp-Proxy-Pool"><a href="#Proxy-amp-Proxy-Pool" class="headerlink" title="Proxy &amp; Proxy Pool"></a>Proxy &amp; Proxy Pool</h1><p>代理为别人的 IP 防止被封</p>
<p>免费代理：<a target="_blank" rel="noopener" href="https://ip.ihuan.me">https://ip.ihuan.me</a></p>
<p>代理池：<a target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/ProxyPool">https://github.com/Python3WebSpider/ProxyPool</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">request_url</span>(<span class="params">url, proxies</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        res = requests.get(url, proxies=proxies)</span><br><span class="line">        <span class="keyword">if</span> res.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> res.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    proxies = &#123;</span><br><span class="line">        <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;http://119.13.103.211:4153&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;https://119.13.103.211:4153&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    html = request_url(<span class="string">&#x27;http://httpbin.org/get&#x27;</span>, proxies=proxies)</span><br><span class="line">    <span class="built_in">print</span>(html)</span><br></pre></td></tr></table></figure>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;show_env&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;headers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;Accept-Encoding&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;Host&quot;</span><span class="punctuation">:</span> <span class="string">&quot;httpbin.org&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;User-Agent&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python-requests/2.31.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;X-Amzn-Trace-Id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Root=1-63156d33-528b16b838892ff15c5a4d2f&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;X-Forwarded-For&quot;</span><span class="punctuation">:</span> <span class="string">&quot;119.13.103.211&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;X-Forwarded-Port&quot;</span><span class="punctuation">:</span> <span class="string">&quot;80&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;X-Forwarded-Proto&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;origin&quot;</span><span class="punctuation">:</span> <span class="string">&quot;119.13.103.211&quot;</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://httpbin.org/get?show_env&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<h1 id="Log-in-Sign-in"><a href="#Log-in-Sign-in" class="headerlink" title="Log in / Sign in"></a>Log in / Sign in</h1><p>Cookies、抓包再提交form（这个还是别用了，抓到的密码肯定是加密的，里面说不定混了其他身份信息，导致封号）、Selenium模拟手动登录</p>
<h2 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h2><p>见1.3 和前面的每个Demo</p>
<h2 id="POST-Request-1"><a href="#POST-Request-1" class="headerlink" title="POST Request"></a>POST Request</h2><p>见 1.2 和 3</p>
<h2 id="Selenium-模拟手动登陆"><a href="#Selenium-模拟手动登陆" class="headerlink" title="Selenium 模拟手动登陆"></a>Selenium 模拟手动登陆</h2><p>伪代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">username = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">&quot;帐号的selector&quot;</span>)))</span><br><span class="line">password = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, <span class="string">&quot;密码的selector&quot;</span>)))</span><br><span class="line">submit = wait.until(EC.element_to_be_clickable((By.XPATH, <span class="string">&#x27;按钮的xpath&#x27;</span>)))</span><br><span class="line"></span><br><span class="line">username.send_keys(<span class="string">&#x27;你的帐号&#x27;</span>)</span><br><span class="line">password.send_keys(<span class="string">&#x27;你的密码&#x27;</span>)submit.click()</span><br></pre></td></tr></table></figure>
<p>为了效率，可以在登录过后得到的cookie维护起来，然后调用requests或者scrapy等进行数据采集，这样数据采集的速度可以得到保证。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cookies = webdriver.get_cookies()</span><br></pre></td></tr></table></figure>
<h1 id="CAPTCHA-Recognize"><a href="#CAPTCHA-Recognize" class="headerlink" title="CAPTCHA Recognize"></a>CAPTCHA Recognize</h1><p>图形验证码：字符识别、字符识别后算数、空间推理（“请点击除了H以外的另一个倾斜字符”，我没遇到过）</p>
<p>行为验证码：滑动拼图、语序点选文字</p>
<p>这里有个项目，README 说原理是通过 selenium 绕过登陆验证，应该首先考虑绕过验证，无法绕过时再考虑通过验证。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Kr1s77/awesome-python-login-model">https://github.com/Kr1s77/awesome-python-login-model</a></p>
<p>绕不过去的时候去这里找个合适的 SDK 让爬虫程序过验证：<a target="_blank" rel="noopener" href="https://github.com/topics/captcha">captcha · GitHub Topics</a></p>
<h2 id="Character-CAPTCHA-Recognize"><a href="#Character-CAPTCHA-Recognize" class="headerlink" title="Character CAPTCHA Recognize"></a>Character CAPTCHA Recognize</h2><p>作者那时候还是使用传统数字图像处理方法，现在已经可以直接用 AI 了，除了找现成库以外还找网站获取验证码识别 API。</p>
<h2 id="Slider-CAPTCHA-Recognize"><a href="#Slider-CAPTCHA-Recognize" class="headerlink" title="Slider CAPTCHA Recognize"></a>Slider CAPTCHA Recognize</h2><p>手搓行为验证码识别稍微难点，要破解图片（部分网站无法直接获取图片）、识别缺口（这个似乎可以直接用图像处理的方法，毕竟缺口一般是很明显的，尝试cv2.matchTemplate），还需要匀速直线拖动（这个应该是全网站通用的）。</p>
<h2 id="SDK-Recommend"><a href="#SDK-Recommend" class="headerlink" title="SDK Recommend"></a>SDK Recommend</h2><p>付费 API，1¥最多100次，个人用（抢课、抢讲座）足够：<a target="_blank" rel="noopener" href="http://www.chaojiying.com/">http://www.chaojiying.com/</a> </p>
<p>免费 SDK：<a target="_blank" rel="noopener" href="https://github.com/sml2h3/ddddocr">https://github.com/sml2h3/ddddocr</a></p>
<p>这个库结合了DL和传统图像处理方法，能做到通用验证码识别，有 Python Library。</p>
<p><code>pip install ddddocr</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205095946047.png" alt="image-20231205095945104"></p>
<p>已知的一个问题（#29）是提供的模型不能区分大小写。</p>
<h1 id="Appium-Install"><a href="#Appium-Install" class="headerlink" title="Appium Install"></a>Appium Install</h1><p>Appium 是一个和 Selenium 功能相同的自动化测试软件，区别在于 Appium 对移动设备的支持更好。</p>
<p>offical doc: <a target="_blank" rel="noopener" href="http://appium.io/">http://appium.io/</a></p>
<p>迪原创新 blog：<a target="_blank" rel="noopener" href="https://www.dilatoit.com/zh/cn-blog/，提供了很多爬虫、自动化测试实践。">https://www.dilatoit.com/zh/cn-blog/，提供了很多爬虫、自动化测试实践。</a></p>
<p>安装平台：</p>
<p>brew：跟 windows 的 Winget 和 ubuntu 的 apt-get 差不多，下载开源源码并编译为程序，比较好用。</p>
<p>—cask：下载编译好的软件包（一些闭源软件的.dmg/.pkg）</p>
<p>npm：appium基于nodejs构建的，所以用这个编译。</p>
<h2 id="Install-Appium"><a href="#Install-Appium" class="headerlink" title="Install Appium"></a>Install Appium</h2><p><code>npm install --location=global appium</code></p>
<p>或</p>
<p><code>npm i -g appium</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205105521805.png" alt="image-20231205105521253"></p>
<h2 id="Install-Driver-from-Appium"><a href="#Install-Driver-from-Appium" class="headerlink" title="Install Driver from Appium"></a>Install Driver from Appium</h2><h3 id="Android"><a href="#Android" class="headerlink" title="Android"></a>Android</h3><p><code>appium driver install uiautomator2</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205165419793.png" alt="image-20231205165418973"></p>
<h3 id="iOS"><a href="#iOS" class="headerlink" title="iOS"></a>iOS</h3><p>中文互联网上的纯 WebDriverAgent 方案已弃用，Appium 2 现使用 XCUITest，其基于 <a target="_blank" rel="noopener" href="https://developer.apple.com/documentation/xctest">XCTest</a> 和 <a target="_blank" rel="noopener" href="https://github.com/appium/WebDriverAgent">WebDriverAgent</a>。</p>
<p>offical doc: <a target="_blank" rel="noopener" href="https://appium.github.io/appium-xcuitest-driver">https://appium.github.io/appium-xcuitest-driver</a></p>
<p><code>appium driver install xcuitest</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231207141023924.png" alt="image-20231207141023479"></p>
<h2 id="Install-Driver’s-Dependencies"><a href="#Install-Driver’s-Dependencies" class="headerlink" title="Install Driver’s Dependencies"></a>Install Driver’s Dependencies</h2><h3 id="Android-1"><a href="#Android-1" class="headerlink" title="Android"></a>Android</h3><p>如果你不需要进行 Android 开发和 Java 开发，那么只需要安装 SKD 和 JDK（免费开源的OpenJDK，不是Oracle JDK），不需要 Android Studio 和 JAVA。</p>
<h4 id="SDK-Cmdline-Tools-amp-SDK-Platform-Tools"><a href="#SDK-Cmdline-Tools-amp-SDK-Platform-Tools" class="headerlink" title="SDK Cmdline-Tools &amp; SDK Platform-Tools"></a>SDK Cmdline-Tools &amp; SDK Platform-Tools</h4><p><strong>重要.</strong> 通过brew安装的 tools 和 platform-tools 在两个目录下，其他软件没办法通过 ANDROID_HOME 目录同时检测到他们，所以除非单独使用，否则不要用这种方法。</p>
<p>下载新版 SDK Cmdline-Tools（SDK Tools 已<a target="_blank" rel="noopener" href="https://developer.android.com/studio/releases/sdk-tools?hl=zh-cn">弃用</a>）和 SDK Platform-tools</p>
<p><a target="_blank" rel="noopener" href="https://developer.android.com/studio?hl=zh-cn#downloads">下载 Android Studio 和应用工具 - Android 开发者  | Android Developers</a></p>
<p><a target="_blank" rel="noopener" href="https://developer.android.com/studio/releases/platform-tools?hl=zh-cn">SDK 平台工具版本说明  | Android 开发者  | Android Developers</a></p>
<p>手动创建 sdk 目录（下面这俩是伪代码，只能逐级创建）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /Users/wanpengxu/Library/Android/sdk</span><br><span class="line"><span class="built_in">mkdir</span> /Users/wanpengxu/Library/Android/sdk/cmdline-tools</span><br></pre></td></tr></table></figure>
<p>移动文件夹并重命名（一定要在 latest 目录下，否则 sdkmanager 不能安装东西）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /Users/wanpengxu/Library/Android/sdk</span><br><span class="line"><span class="built_in">mv</span> /Users/wanpengxu/Downloads/cmdline-tools ./cmdline-tools/latest</span><br><span class="line"><span class="built_in">mv</span> /Users/wanpengxu/Downloads/platform-tools ./</span><br></pre></td></tr></table></figure>
<p>手动配置环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export ANDROID_HOME=&quot;/Users/wanpengxu/Library/Android/sdk&quot;&#x27;</span> &gt;&gt; ~/.zshrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export PATH=&quot;$PATH:$ANDROID_HOME/cmdline-tools/latest:$ANDROID_HOME/platform-tools&quot;&#x27;</span> &gt;&gt; ~/.zshrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export PATH=&quot;$PATH:$ANDROID_HOME/cmdline-tools/latest/bin&quot;&#x27;</span> &gt;&gt; ~/.zshrc</span><br></pre></td></tr></table></figure>
<p><code>:</code>是 MacOS 环境变量的分割符，要确保以前的环境变量存在就要加 <code>:$PATH</code>（新的加在前面）或者 <code>$PATH:</code> （新的加在后面）</p>
<p>新版 SDK Cmdline-Tools 不集成 emulator，自己安装</p>
<p><code>sdkmanager &quot;emulator&quot;</code></p>
<p>还要再装一个 build-tools，虽然不会被检测，但是是必须要用的</p>
<p>安装时必须指定版本，在这里查看版本：<a target="_blank" rel="noopener" href="https://developer.android.com/studio/releases/build-tools?hl=zh-cn#kts">SDK Build Tools 版本说明  | Android 开发者  | Android Developers</a></p>
<p><code>sdkmanager &quot;build-tools;34.0.0&quot;</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205170708118.png" alt="image-20231205170707666"></p>
<h4 id="Openjdk"><a href="#Openjdk" class="headerlink" title="Openjdk"></a>Openjdk</h4><p><code>brew install openjdk</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205114259595.png" alt="image-20231205114258922"></p>
<p>提示我们要配置环境变量</p>
<p>通过查看目录发现 brew 为我们创建了一个软链接，拿它作为 <code>JAVA_HOME</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export JAVA_HOME=&quot;/opt/homebrew/opt/java&quot;&#x27;</span> &gt;&gt; ~/.zshrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;export PATH=&quot;$PATH:$JAVA_HOME/bin&quot;&#x27;</span> &gt;&gt; ~/.zshrc</span><br></pre></td></tr></table></figure>
<p>其实我觉得更改 <code>/etc/paths</code> 这种方式跟 windows 配置环境变量更像，但是 unix 系统好像都是写在命令行启动脚本里。</p>
<p>重启命令行或重载启动脚本后可用 java 命令。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205114706969.png" alt="image-20231205114706408"></p>
<h3 id="iOS-1"><a href="#iOS-1" class="headerlink" title="iOS"></a>iOS</h3><h4 id="Xcode-amp-Xcode-Command-Line-Tools"><a href="#Xcode-amp-Xcode-Command-Line-Tools" class="headerlink" title="Xcode &amp; Xcode Command Line Tools"></a>Xcode &amp; Xcode Command Line Tools</h4><p>直接从 Apple Store 里装</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205163243835.png" alt="image-20231205163243186"></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205164001398.png" alt="image-20231205164000715"></p>
<p>CLT要<strong>重新选择</strong>一下，原本会显示（No CLT Selected）。</p>
<h4 id="WDA"><a href="#WDA" class="headerlink" title="WDA"></a>WDA</h4><p>下载源码：<a target="_blank" rel="noopener" href="https://github.com/appium/WebDriverAgent">https://github.com/appium/WebDriverAgent</a></p>
<p>打开Xcode进行编译安装</p>
<p>前提条件：登陆账户、下载 iOS 开发平台</p>
<h2 id="Install-Library-in-Language"><a href="#Install-Library-in-Language" class="headerlink" title="Install Library in Language"></a>Install Library in Language</h2><p><code>pip install Appium-Python-Client</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205141256173.png" alt="image-20231205141255431"></p>
<h2 id="Install-Appium-Inspector-new-Appium-Desktop"><a href="#Install-Appium-Inspector-new-Appium-Desktop" class="headerlink" title="Install Appium Inspector (new Appium Desktop)"></a>Install Appium Inspector (new Appium Desktop)</h2><p><a target="_blank" rel="noopener" href="https://github.com/appium/appium-inspector/releases">Releases · appium/appium-inspector (github.com)</a></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205141859468.png" alt="image-20231205141858798"></p>
<h2 id="Check"><a href="#Check" class="headerlink" title="Check"></a>Check</h2><p><code>npm install -g @appium/doctor</code>（appium-doctor 已弃用）</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205164129270.png" alt="image-20231205164128766"></p>
<p>necessary 项全绿就可以了。</p>
<h1 id="Appium-Run"><a href="#Appium-Run" class="headerlink" title="Appium Run"></a>Appium Run</h1><p>启动 appium server</p>
<p><code>appium</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205165449763.png" alt="image-20231205165449003"></p>
<p>获取 activity</p>
<p><code>adb shell dumpsys activity top | grep ACTIVITY</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205164907976.png" alt="image-20231205164907278"></p>
<p>启动 appium inspector，capabilities 只填写最基本的两项，点击两次 Start Session。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205172826632.png" alt="image-20231205172825773"></p>
<p>在这里可以获取元素的 XPath，也可以录制行为查看其对应脚本。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231205173134252.png" alt="image-20231205173133668"></p>
<p>由于官方测试的 Battery 在 MIUI 中不在第一页显示范围内，需要 gesture，所以还是选择第一页的元素进行点击测试吧。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> unittest</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> appium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> appium.options.android <span class="keyword">import</span> UiAutomator2Options</span><br><span class="line"><span class="keyword">from</span> appium.webdriver.common.appiumby <span class="keyword">import</span> AppiumBy</span><br><span class="line"></span><br><span class="line">capabilities = <span class="built_in">dict</span>(</span><br><span class="line">    platformName=<span class="string">&#x27;Android&#x27;</span>,</span><br><span class="line">    automationName=<span class="string">&#x27;uiautomator2&#x27;</span>,</span><br><span class="line">    deviceName=<span class="string">&#x27;Android&#x27;</span>,</span><br><span class="line">    appPackage=<span class="string">&#x27;com.android.settings&#x27;</span>,</span><br><span class="line">    appActivity=<span class="string">&#x27;.MainSettings&#x27;</span>,</span><br><span class="line">    language=<span class="string">&#x27;en&#x27;</span>,</span><br><span class="line">    locale=<span class="string">&#x27;US&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">appium_server_url = <span class="string">&#x27;http://localhost:4723&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestAppium</span>(unittest.TestCase):</span><br><span class="line">    <span class="comment"># 每个测试前调用</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">setUp</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.driver = webdriver.Remote(appium_server_url, options=UiAutomator2Options().load_capabilities(capabilities))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每个测试完成后调用</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">tearDown</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># time.sleep(1)</span></span><br><span class="line">        <span class="comment"># if self.driver:</span></span><br><span class="line">        <span class="comment">#     self.driver.quit()</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 以&#x27;test_&#x27;开头的一个测试方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">test_find_battery</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        el = self.driver.find_element(by=AppiumBy.XPATH, value=<span class="string">&#x27;//*[@text=&quot;WLAN&quot;]&#x27;</span>)</span><br><span class="line">        el.click()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    unittest.main()</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">----------------------------------------------------------------------</span><br><span class="line">Ran 1 test in 5.717s</span><br><span class="line"></span><br><span class="line">OK</span><br></pre></td></tr></table></figure>
<p>脚本启动后会把 appium inspector 的 session 顶掉，再次使用时需要重新 start session。</p>
<h1 id="Demo-7-知乎-Android-版文章"><a href="#Demo-7-知乎-Android-版文章" class="headerlink" title="Demo 7: 知乎 Android 版文章"></a>Demo 7: 知乎 Android 版文章</h1><h2 id="代码实现-6"><a href="#代码实现-6" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> appium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> appium.options.android <span class="keyword">import</span> UiAutomator2Options</span><br><span class="line"><span class="keyword">from</span> appium.webdriver.common.appiumby <span class="keyword">import</span> AppiumBy</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">capabilities = <span class="built_in">dict</span>(</span><br><span class="line">    platformName=<span class="string">&#x27;Android&#x27;</span>,</span><br><span class="line">    automationName=<span class="string">&#x27;uiautomator2&#x27;</span>,</span><br><span class="line">    deviceName=<span class="string">&#x27;Android&#x27;</span>,</span><br><span class="line">    appPackage=<span class="string">&#x27;com.zhihu.android&#x27;</span>,</span><br><span class="line">    appActivity=<span class="string">&#x27;.app.ui.activity.MainActivity&#x27;</span>,</span><br><span class="line">    language=<span class="string">&#x27;en&#x27;</span>,</span><br><span class="line">    locale=<span class="string">&#x27;US&#x27;</span>,</span><br><span class="line">    noReset=<span class="literal">True</span>  <span class="comment"># 不要重置 session</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">appium_server_url = <span class="string">&#x27;http://localhost:4723&#x27;</span></span><br><span class="line"></span><br><span class="line">driver = webdriver.Remote(appium_server_url, options=UiAutomator2Options().load_capabilities(capabilities))</span><br><span class="line"></span><br><span class="line">time.sleep(<span class="number">6</span>)   <span class="comment"># 等广告</span></span><br><span class="line"></span><br><span class="line">input_elem1 = driver.find_element(AppiumBy.ID, <span class="string">&#x27;com.zhihu.android:id/query_container&#x27;</span>)</span><br><span class="line">input_elem1.click()</span><br><span class="line"></span><br><span class="line">input_elem2 = driver.find_element(AppiumBy.ID, <span class="string">&#x27;com.zhihu.android:id/input&#x27;</span>)</span><br><span class="line">input_elem2.send_keys(<span class="string">&#x27;科研实习&#x27;</span>)</span><br><span class="line"></span><br><span class="line">search_elem = driver.find_element(AppiumBy.ID, <span class="string">&#x27;com.zhihu.android:id/cancel&#x27;</span>)</span><br><span class="line">search_elem.click()</span><br><span class="line"></span><br><span class="line">filter_elem = driver.find_element(AppiumBy.ID, <span class="string">&#x27;com.zhihu.android:id/classify_filter_btn&#x27;</span>)</span><br><span class="line">filter_elem.click()</span><br><span class="line"></span><br><span class="line">passage_elem = driver.find_element(AppiumBy.XPATH, <span class="string">&#x27;//*[@text=&quot;只看文章&quot;]&#x27;</span>)</span><br><span class="line">passage_elem.click()</span><br><span class="line">filter_elem.click()</span><br><span class="line"></span><br><span class="line"><span class="comment"># driver.swipe(555, 1500, 555, 1300, duration=300)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    item_elems = driver.find_elements(AppiumBy.XPATH, <span class="string">&#x27;//android.view.View[@resource-id=&quot;root&quot;]/android.view.View/android.view.View/android.widget.ListView/android.view.View&#x27;</span>)    <span class="comment"># 获取android.widget.ListView的所有直接子节点</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_elems:</span><br><span class="line">        text_part = item.find_elements(AppiumBy.CLASS_NAME, <span class="string">&#x27;android.widget.TextView&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(text_part) == <span class="number">0</span> <span class="keyword">or</span> text_part[<span class="number">0</span>].text == <span class="string">&#x27;相关搜索&#x27;</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="built_in">print</span>(text_part[<span class="number">0</span>].text)</span><br><span class="line">    driver.swipe(<span class="number">555</span>, <span class="number">1850</span>, <span class="number">555</span>, <span class="number">500</span>, duration=<span class="number">300</span>)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">【长期有效】北京大学科研实习招募</span><br><span class="line">科研实习丨清华大学智能计算实验室招收科研助理/实习生 (可远程)</span><br><span class="line">科研实习丨清华大学交叉信息研究院招收科研实习生</span><br><span class="line">抓紧！一大波大厂＆科研实习机会可别错过（含腾讯AI Lab,清华大学课题组）</span><br><span class="line">科研实习 | 腾讯优图(深圳)实验室实习生招聘</span><br><span class="line">清华赵行老师，招收视觉/机器人科研实习生</span><br><span class="line">HISLab招收暑期科研实习生（可远程）5.2</span><br><span class="line">科研实习丨香港科技大学统计机器学习实验室招收科研实习生(目前为远程)</span><br><span class="line">科研实习 | 北大贺笛老师招收GNN方向科研实习生</span><br><span class="line">科研实习 | 北大张文涛教授招收GNN科研实习生/RA</span><br><span class="line">科研实习丨北京大学国际机器学习研究中心招收科研实习生/RA</span><br><span class="line">【实习内推】中科院-科研助理实习生</span><br><span class="line">【实习内推】中科院-科研助理实习生</span><br><span class="line">美团广告平台模型组科研实习生招聘</span><br><span class="line">科研招聘 |上海人工智能实验室招聘实习生</span><br><span class="line">独家解读丨科研实习该怎么找、怎么做</span><br><span class="line">科研实习丨西湖大学2023年暑期科研实习公告</span><br><span class="line">科研实习丨西湖大学2023年暑期科研实习公告</span><br><span class="line">美团广告平台模型组科研实习生招聘</span><br><span class="line">科研实习丨麻省理工学院韩松教授实验室招收科研实习生(可远程)</span><br><span class="line">UC Santa Cruz王鑫教授招收多名暑期科研实习生（summer 2022， NLP/CV/AI）</span><br></pre></td></tr></table></figure>
<h2 id="实现细节-6"><a href="#实现细节-6" class="headerlink" title="实现细节"></a>实现细节</h2><p>不同于从浏览器直接获取 HTML response，这种通过 Appium 对 screenshot 逆向取得 XML 的方式只能获取到显示的内容，不能获取到没显示的内容（文字后的超链接、截断前的字符串等等）。</p>
<h3 id="通过-XPath-获取元素的所有直接子节点"><a href="#通过-XPath-获取元素的所有直接子节点" class="headerlink" title="通过 XPath 获取元素的所有直接子节点"></a>通过 XPath 获取元素的所有直接子节点</h3><p>因为逆向出的 XML 信息不全导致筛选困难，无法精确捕获 item 所在的元素，所以最好尽可能通过 <code>//</code> 定位到树结构的分岔点，然后通过 <code>/</code> 按父子关系选出所有直接子节点。</p>
<p>顺带一提，获取所有的子节点用的是 <code>//node()</code></p>
<h3 id="信息获取逻辑"><a href="#信息获取逻辑" class="headerlink" title="信息获取逻辑"></a>信息获取逻辑</h3><p>因为每个 screenshot 都是独立的，因此滑动后的页面和滑动前的页面无法联系起来，所以最好处理完滑动前页面的所有信息，再进行滑动，又因为滑动操作无法智能地将滑动后的页面完全与滑动前的页面分离、没有重叠，因此每次获取页面的信息都可能会发生重复。</p>
<h1 id="Write-to-MySQL"><a href="#Write-to-MySQL" class="headerlink" title="Write to MySQL"></a>Write to MySQL</h1><p>与 MySQL 数据库交互主要有这几个库， PyMySQL, MySQLClient, SQLAlchemy。第一个是 pyhton 实现，第二个是 C 实现，第三个可以配合 pandas 将 csv 写入 mysql。</p>
<p>我觉得会个 pymysql 就行了，使用方法很简单，把 mysql 语句装进字符串即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 connect 方法，传入数据库地址，账号密码，数据库名，得到数据库对象</span></span><br><span class="line">db = pymysql.connect(<span class="string">&quot;localhost&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;root&quot;</span>, <span class="string">&quot;test_library&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取 cursor 准备操作数据库</span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 往表中插入一条记录</span></span><br><span class="line">sql = <span class="string">&quot;insert into test_table(name, age) values (&#x27;WanpengXu&#x27;, 22)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    cursor.execute(sql)</span><br><span class="line">    <span class="comment"># 提交</span></span><br><span class="line">    db.commit()</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="comment"># 回滚</span></span><br><span class="line">    db.rollback()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭数据库的连接</span></span><br><span class="line">db.close()</span><br></pre></td></tr></table></figure>
<h1 id="Write-to-MongoDB"><a href="#Write-to-MongoDB" class="headerlink" title="Write to MongoDB"></a>Write to MongoDB</h1><p>MongoDB 是一种非关系型数据库（NOSQL，Not Only SQL），它不以二维表的形式存储数据，而是以 JSON （键值对）的形式存储数据。</p>
<p>没什么用，不用学。</p>
<h1 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h1><p>Scrapy 是一个爬虫框架，集成了请求（requests）、解析（beautifulsoup）、存储（csv, xlwt, json）这些操作。</p>
<p>scrapy 同时还是一个独立的程序，你可以直接调用它而不需经过 python。</p>
<p>以下一节中要爬的网站 <code>https://tianchi.aliyun.com/competition/activeList</code> 为例。</p>
<p><code>pip install scrapy</code></p>
<p>首先新建 scrapy 项目</p>
<p><code>scrapy startproject tianchi</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231208143223868.png" alt="image-20231208143223160"></p>
<p>其中，</p>
<p><code>spiders</code>：存放爬虫代码的目录</p>
<p><code>items.py</code>：定义存储数据的字段</p>
<p><code>middlewares.py</code>：中间件，爬虫响应间歇执行的代码</p>
<p><code>pipelines.py</code>：定义存储目标的信息，如连接 MySQL 所需的信息</p>
<p><code>settings.py</code>：定义爬虫的配置，如 header信息</p>
<p>点击 page 后发现不是通过 GET Request 或者 url，而是对一个 api 进行了 GET Request，返回 JSON 数据。</p>
<p><code>pageNum=2</code> 代表第2页，<code>pageSize=10</code> 代表获取10个， <code>state=1</code> 代表活跃竞赛</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231208152730571.png" alt="image-20231208152729961"></p>
<p>所以我们可以不用解析 HTML 了，直接对这个 api 进行 GET request，获取 JSON。</p>
<p>生成 spider 文件</p>
<p><code>scrapy genspider tianchi_spider &quot;https://tianchi.aliyun.com/competition/proxy/api/competition/api/race/listBrief?pageNum=1&amp;pageSize=10&amp;state=1&quot;</code></p>
<p>自动生成的 <code>tianchi_spider.py</code> 文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TianchiSpiderSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;tianchi_spider&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;tianchi.aliyun.com&quot;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;http://tianchi.aliyun.com/&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>简单修改查看是否能获取到 response</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TianchiSpiderSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;tianchi_spider&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;tianchi.aliyun.com&quot;</span>]</span><br><span class="line">    start_urls = [<span class="string">&quot;http://tianchi.aliyun.com/&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;test.html&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></table></figure>
<p><code>scrapy crawl tianchi_spider -o tianchi.json</code></p>
<p>如果能够成功获取网页内容则成功。</p>
<h1 id="Splash"><a href="#Splash" class="headerlink" title="Splash"></a>Splash</h1><p>Splash 是一个 JavaScript 渲染服务，是一个带有 HTTP API 的轻量级浏览器，它可以和 Scrapy 配合实现动态渲染页面的抓取，和 selenium 的效果差不多，不过它并不是模拟人工操作浏览器。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>brew install --cask --appdir=/Applications docker</code></p>
<p>点开 docker 简单配置一下。</p>
<p>pull splash 镜像</p>
<p><code>docker pull scrapinghub/splash</code></p>
<p>在 8050 port 上 run splash 镜像</p>
<p><code>docker run -p 8050:8050 scrapinghub/splash</code></p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231209201425631.png" alt="image-20231209201425062"></p>
<p><code>pip install scrapy-splash</code></p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>在 scrapy 生成的 setting.py 任意位置插入以下代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SPLASH_URL = <span class="string">&#x27;http://localhost:8050&#x27;</span></span><br><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">&#x27;scrapy_splash.SplashCookiesMiddleware&#x27;</span>: <span class="number">723</span>,</span><br><span class="line">    <span class="string">&#x27;scrapy_splash.SplashMiddleware&#x27;</span>: <span class="number">725</span>,</span><br><span class="line">    <span class="string">&#x27;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#x27;</span>: <span class="number">810</span>,</span><br><span class="line">&#125;</span><br><span class="line">SPIDER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">&#x27;scrapy_splash.SplashDeduplicateArgsMiddleware&#x27;</span>: <span class="number">100</span>,</span><br><span class="line">&#125;</span><br><span class="line">DUPEFILTER_CLASS = <span class="string">&#x27;scrapy_splash.SplashAwareDupeFilter&#x27;</span></span><br><span class="line">HTTPCACHE_STORAGE = <span class="string">&#x27;scrapy_splash.SplashAwareFSCacheStorage&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>使用 SplashRequest 替换 Scrapy 的 Request 即可获取渲染后的网页。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest</span><br><span class="line"></span><br><span class="line">        <span class="comment"># yield scrapy.Request(url=&#x27;https://tianchi.aliyun.com/competition/activeList&#x27;, callback=self.parse_total_pages)</span></span><br><span class="line">        <span class="keyword">yield</span> SplashRequest(url=<span class="string">&#x27;https://tianchi.aliyun.com/competition/activeList?lang=zh-cn&#x27;</span>, callback=self.parse_total_pages)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="Demo-8-阿里天池-活跃中的竞赛"><a href="#Demo-8-阿里天池-活跃中的竞赛" class="headerlink" title="Demo 8: 阿里天池 活跃中的竞赛"></a>Demo 8: 阿里天池 活跃中的竞赛</h1><h2 id="分析-4"><a href="#分析-4" class="headerlink" title="分析"></a>分析</h2><p>该网页采用了 ajax 技术，直接获取 html 什么都没有，这时就要使用 Splash 来获取渲染后的页面。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231209195637729.png" alt="image-20231209195636233"></p>
<p>这个 demo 和一般的爬取不太一样，主页面和获取数据的页面不是一个。所以，首先请求的 url 应该是主页面，获取到主页面的 html 后交给 解析出所有页码的方法，然后将每个页码拼成获取数据的 url，分别交给 解析出数据的方法。共需要 3 个方法。</p>
<h2 id="代码实现-7"><a href="#代码实现-7" class="headerlink" title="代码实现"></a>代码实现</h2><p>setting.py 按照上一章添加</p>
<p>items.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TianchiItem</span>(scrapy.Item):</span><br><span class="line">    race_name = scrapy.Field()</span><br><span class="line">    brief = scrapy.Field()</span><br><span class="line">    race_type = scrapy.Field()</span><br><span class="line">    bonus = scrapy.Field()</span><br><span class="line">    team_num = scrapy.Field()</span><br><span class="line">    ddl = scrapy.Field()</span><br></pre></td></tr></table></figure>
<p>tianchi_spider.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> tianchi.items <span class="keyword">import</span> TianchiItem</span><br><span class="line"><span class="keyword">from</span> scrapy_splash <span class="keyword">import</span> SplashRequest</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TianchiSpiderSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&quot;tianchi_spider&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&quot;tianchi.aliyun.com&quot;</span>]</span><br><span class="line">    <span class="comment"># start_urls = [&quot;https://tianchi.aliyun.com/competition/proxy/api/competition/api/race/listBrief?pageNum=1&amp;pageSize=10&amp;state=1&quot;]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">start_requests</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 发送起始请求，获取总页数</span></span><br><span class="line">        <span class="comment"># yield scrapy.Request(url=&#x27;https://tianchi.aliyun.com/competition/activeList&#x27;, callback=self.parse_total_pages)</span></span><br><span class="line">        <span class="keyword">yield</span> SplashRequest(url=<span class="string">&#x27;https://tianchi.aliyun.com/competition/activeList?lang=zh-cn&#x27;</span>, callback=self.parse_total_pages)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_total_pages</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="comment"># 在这个回调函数中获取总页数</span></span><br><span class="line">        total_pages = <span class="built_in">int</span>(response.css(<span class="string">&#x27;li.ant-pagination-item::attr(title)&#x27;</span>).getall()[-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构造每一页的请求</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, total_pages + <span class="number">1</span>):</span><br><span class="line">            page_url = <span class="string">f&#x27;https://tianchi.aliyun.com/competition/proxy/api/competition/api/race/listBrief?pageNum=<span class="subst">&#123;page&#125;</span>&amp;pageSize=10&amp;state=1&#x27;</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=page_url, callback=self.parse_page)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_page</span>(<span class="params">self, response</span>):</span><br><span class="line">        items_dict = json.loads(response.text)</span><br><span class="line">        <span class="keyword">for</span> item_dict <span class="keyword">in</span> items_dict[<span class="string">&#x27;data&#x27;</span>][<span class="string">&#x27;list&#x27;</span>]:</span><br><span class="line">            item = TianchiItem()</span><br><span class="line">            item[<span class="string">&#x27;race_name&#x27;</span>] = item_dict[<span class="string">&#x27;raceName&#x27;</span>]</span><br><span class="line">            item[<span class="string">&#x27;brief&#x27;</span>] = item_dict[<span class="string">&#x27;brief&#x27;</span>]</span><br><span class="line">            item[<span class="string">&#x27;race_type&#x27;</span>] = item_dict[<span class="string">&#x27;raceType&#x27;</span>]</span><br><span class="line">            item[<span class="string">&#x27;bonus&#x27;</span>] = <span class="string">f&quot;<span class="subst">&#123;item_dict[<span class="string">&#x27;currencySymbol&#x27;</span>]&#125;</span><span class="subst">&#123;item_dict[<span class="string">&#x27;bonus&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line">            item[<span class="string">&#x27;team_num&#x27;</span>] = item_dict[<span class="string">&#x27;teamNum&#x27;</span>]</span><br><span class="line">            item[<span class="string">&#x27;ddl&#x27;</span>] = item_dict[<span class="string">&#x27;currentSeasonEnd&#x27;</span>]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<p><code>scrapy crawl tianchi_spider -o tianchi.json</code></p>
<p>等待渲染的时间比较长，30s 多。</p>
<p><img src="https://testingcf.jsdelivr.net/gh/WanpengXu/myPicGo/img/ms20231209211155542.png" alt="image-20231209211154960"></p>
<p>可以发现页间的顺序是不固定的，这是多线程爬取导致的。</p>
<p>但是写入文件真的太方便了，不用自己处理多线程的冲突问题。</p>
<h2 id="实现细节-7"><a href="#实现细节-7" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="回调（callback）"><a href="#回调（callback）" class="headerlink" title="回调（callback）"></a>回调（callback）</h3><p>这个在 java 中经常用到，在 scrapy 里代表方法执行完成后不离开调用者去赋值而是回去调用另一个方法直到不需要再被回调。</p>
<h3 id="json-转-python-dict"><a href="#json-转-python-dict" class="headerlink" title="json 转 python dict"></a>json 转 python dict</h3><p>用 <code>json.loads()</code></p>
<h3 id="逻辑顺序"><a href="#逻辑顺序" class="headerlink" title="逻辑顺序"></a>逻辑顺序</h3><p>scrapy 默认是多线程的，所以尽量用递归（在这里是回调）来写，不要用到顺序逻辑和循环逻辑。</p>
<h3 id="选择器"><a href="#选择器" class="headerlink" title="选择器"></a>选择器</h3><p>主要用 <code>response.xpath()</code> 和 <code>response.css()</code></p>
<p>更多见：<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/selectors.html">Selectors — Scrapy 2.11.0 documentation</a></p>
<h1 id="反爬"><a href="#反爬" class="headerlink" title="反爬"></a>反爬</h1><p>本来不打算写这个的，好朋友最近要爬一个gov网站，selenium被检测出来了（“正受到自动化测试软件的控制”），这时可以用undetected_chromedriver。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> undetected_chromedriver <span class="keyword">as</span> uc</span><br><span class="line">driver = uc.Chrome()</span><br></pre></td></tr></table></figure>
<p>即可。</p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>许</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://xuwp.top/Python-Crawler.html">https://xuwp.top/Python-Crawler.html</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2022 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E7%88%AC%E8%99%AB/"># 爬虫</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
            
            <a class="next" rel="next" href="/Digital-Image-Processing.html">M08115: 图像处理与计算机视觉(2023春)</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>Stay hungry. Stay foolish.</span>
    </div>
</footer>

    </div>
</body>

</html>